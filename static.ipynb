{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This is a develop environment for the static website scraper. Functions developed here will be eventually packaged into .py files and called from other notebook or python scripts.\n",
    "\n",
    "\n",
    "**Progress**\n",
    "\n",
    "Done:\n",
    "    1. get response\n",
    "    2. find and extract content\n",
    "    3. save file\n",
    "    4. pagination and batch\n",
    "    5. special encoding\n",
    "    6. rotate agent\n",
    "    \n",
    "Long-term:\n",
    "\n",
    "    - rotate IP\n",
    "    - support authentication \n",
    "    - support cookie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure you install the required libraries\n",
    "\n",
    "# !pip3 install --upgrade requests # library for making request for the static websites\n",
    "# !pip3 install --upgrade soupsieve  # library to support css selector in beautifulsoup\n",
    "# !pip3 install --upgrade beautifulsoup4 # a parser that balances between efficiency and leniency\n",
    "# !pip3 install --upgrade --user lxml # a more efficient parser\n",
    "# !pip3 install --upgrade html5lib # a parser that acts like a browser, most lenient\n",
    "\n",
    "\n",
    "# Key libraries\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "# These functions help us understand the variables that exist in the environment\n",
    "# which is useful for creating natural language interface for data analysis\n",
    "\n",
    "def get_local_variables(ignore_underscore = True):\n",
    "    \"\"\"Get the name and definition of the local variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ignore_underscore : boolean (optional, default = True)\n",
    "        Whether or not the variables starting with \"_\" need to be filtered out.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dictionary\n",
    "        A mapping between name and definition of the local variables.\n",
    "                \n",
    "    \"\"\"\n",
    "    callers_local_vars = dict(inspect.currentframe().f_back.f_locals.items())\n",
    "    if filter_:\n",
    "        var_keys = list(callers_local_vars.keys())\n",
    "        for key in var_keys:\n",
    "            if key.startswith('_'):\n",
    "                del callers_local_vars[key]\n",
    "    return callers_local_vars\n",
    "def retrieve_name(var):\n",
    "    \"\"\"Retrieve the name of the variable. # Reference https://stackoverflow.com/a/40536047.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var: object \n",
    "        Variable to get the name of.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        Name of the variable passed.\n",
    "        \n",
    "    \"\"\"\n",
    "    for fi in reversed(inspect.stack()):\n",
    "        names = [var_name for var_name, var_val in fi.frame.f_locals.items() if var_val is var]\n",
    "        if len(names) > 0:\n",
    "            return names[0]\n",
    "        \n",
    "def get_attributes(obj, ignore_underscore = True):\n",
    "    \"\"\"Get a list of valid attributes of the object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ignore_underscore : boolean (optional, default = True)\n",
    "        Whether or not the variables starting with \"_\" need to be filtered out.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        A list of valid attributes of the object.\n",
    "                \n",
    "    \"\"\"\n",
    "    return [x for x in dir(obj) if not x.startswith('_')]\n",
    "\n",
    "def print_attributes_and_values(obj, ignore_underscore = True):\n",
    "    \"\"\"Print the valid attributes of the object and their corresponding values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ignore_underscore : boolean (optional, default = True)\n",
    "        Whether or not the variables starting with \"_\" need to be filtered out.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "                \n",
    "    \"\"\"\n",
    "    obj_name = retrieve_name(obj)\n",
    "    attributes = get_attributes(obj, ignore_underscore = ignore_underscore)\n",
    "    for attr in attributes:\n",
    "        obj_attr_string = obj_name+'.'+attr\n",
    "        print(obj_attr_string)\n",
    "        print(' '*4 + str(eval(obj_attr_string))[:60])\n",
    "        print('-'*70)\n",
    "\n",
    "\n",
    "def get_response(url, verbose = True):\n",
    "    \"\"\"Get the response of the HTTP GET request for the target url.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url: string\n",
    "        The url to the website that needs to be scraped. \n",
    "    verbose: boolean (optional, default = True)\n",
    "        Whether or not [Success] message should be printed.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    response object\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Reference: https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/    \n",
    "    headers_list = [{'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Referer': 'https://www.google.com/', 'DNT': '1', 'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1'}, {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Referer': 'https://www.google.com/', 'DNT': '1', 'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1'}, {'Connection': 'keep-alive', 'DNT': '1', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'Sec-Fetch-Site': 'none', 'Sec-Fetch-Mode': 'navigate', 'Sec-Fetch-Dest': 'document', 'Referer': 'https://www.google.com/'}, {'Connection': 'keep-alive', 'Upgrade-Insecure-Requests': '1', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9', 'Sec-Fetch-Site': 'same-origin', 'Sec-Fetch-Mode': 'navigate', 'Sec-Fetch-User': '?1', 'Sec-Fetch-Dest': 'document', 'Referer': 'https://www.google.com/'}]\n",
    "    \n",
    "    try:\n",
    "        headers = random.choice(headers_list)\n",
    "        response = requests.get(url, headers = headers)\n",
    "        response.raise_for_status() # Raise Exception when response was not successful\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print('[Error] HTTP error occurred: '+str(http_err))\n",
    "        return requests.models.Response() # Return empty response\n",
    "    except Exception as err:\n",
    "        print('[Error] Other error occurred: '+str(err))\n",
    "        return requests.models.Response() # Return empty response\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('[Success] The website at \"'+url+'\" is collected successfully.')\n",
    "        return response\n",
    "\n",
    "def get_responses(urls, verbose = True):\n",
    "    \"\"\"Get the responses of the HTTP GET requests for the target urls. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    urls: list of string\n",
    "        The urls to the websites that need to be scraped. \n",
    "    verbose: boolean (optional, default = True)\n",
    "        Whether or not [Success] message should be printed.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list of response object\n",
    "        \n",
    "    \"\"\"\n",
    "    return [get_response(url) for url in urls]\n",
    "\n",
    "\n",
    "\n",
    "def get_soup(response, default_parser = 'lxml'):\n",
    "    \"\"\"Get the beautiful soup object of the response object or filepath or html string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    response: requests.models.Response, string\n",
    "        The response object or filepath or html string. \n",
    "    default_parser: string (optional, default = lxml)\n",
    "        Which parser to use when parsing the response.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list of response object\n",
    "        \n",
    "    \"\"\"\n",
    "    if isinstance(response, requests.models.Response):\n",
    "        soup = bs4.BeautifulSoup(response.content, default_parser)\n",
    "    elif isinstance(response, str) and os.path.exists(response):\n",
    "        with open(response) as file_handler:\n",
    "            soup = bs4.BeautifulSoup(file_handler, default_parser)\n",
    "    else:\n",
    "        try:\n",
    "            soup = bs4.BeautifulSoup(response, default_parser)\n",
    "        except Exception as err:\n",
    "            print('[Error] The response object you provided cannot be turned into beautiful soup object: '+str(err))\n",
    "    return soup\n",
    "\n",
    "def save_html(html_object, url , path = ''):\n",
    "    \"\"\"Save the response or soup object as a HTML file at the path provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    html_object: requests.models.Response, bs4.BeautifulSoup\n",
    "        The response or soup object. \n",
    "    path: string (optional, default = ./TEMP.html)\n",
    "        The path at which the HTML file will be saved.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "        \n",
    "    \"\"\"\n",
    "    if path == '':\n",
    "        path = './'+re.sub('^https?://','',url).replace('/','_').replace('.','-')+'.html'\n",
    "    if isinstance(html_object, requests.models.Response):\n",
    "        html_text = html_object.text\n",
    "    elif isinstance(html_object, (bs4.BeautifulSoup,bs4.element.Tag)):\n",
    "        html_text = str(html_object.prettify())\n",
    "    else:\n",
    "        html_text = str(html_object)\n",
    "    try:\n",
    "        with open(path,'w') as f:\n",
    "            f.write(html_text)\n",
    "            print('[Success] The HTML file is saved succesfully.')\n",
    "    except Exception as err:\n",
    "        print('[Error] The response object you provided cannot be turned into beautiful soup object: '+str(err))\n",
    "\n",
    "def is_readable_content(content):\n",
    "    \"\"\"Return whether the content passed is a readable content like Tag or NavigableString; not CData, Comment, Declaration, Doctype, ProcessingInstruction, ResultSet, Script, Stylesheet, XMLFormatter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    content: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    boolean\n",
    "        \n",
    "    \"\"\"\n",
    "    # Types that are instances of NavigableString:  CData, Comment, Declaration, Doctype, PreformattedString, ProcessingInstruction, ResultSet, Script, Stylesheet, TemplateString, XMLFormatter\n",
    "    # Types in the group above that are not String:  CData, Comment, Declaration, Doctype, ProcessingInstruction, ResultSet, Script, Stylesheet, XMLFormatter\n",
    "    return isinstance(content, (bs4.element.Tag, bs4.element.NavigableString)) and not isinstance(content, (bs4.element.CData, bs4.element.Comment, bs4.element.Declaration, bs4.element.Doctype, bs4.element.ProcessingInstruction, bs4.element.ResultSet, bs4.element.Script, bs4.element.Stylesheet, bs4.element.XMLFormatter))\n",
    "\n",
    "def get_contents(element):\n",
    "    \n",
    "    \"\"\"Return a list of non-empty and readable contents/children of the element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    content: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list of bs4.element\n",
    "        \n",
    "    \"\"\"\n",
    "    return [content for content in element.contents if str(content).strip()!='' and is_readable_content(content)]\n",
    "\n",
    "def get_contents_names(element):\n",
    "    \"\"\"Return the list of names of the non-empty and readable contents/children of the element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    content: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list of string\n",
    "        \n",
    "    \"\"\"\n",
    "    return [content.name for content in get_contents(element)]\n",
    "\n",
    "def elevate_till_is_tag(element):\n",
    "    \"\"\"Return the nearest Tag element, if not itself, return its parent if it is a Tag element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    bs4.element.Tag\n",
    "        \n",
    "    \"\"\"\n",
    "    if isinstance(element, bs4.element.NavigableString):\n",
    "        return element.parent\n",
    "    if isinstance(element, bs4.element.Tag):\n",
    "        return element\n",
    "    else:\n",
    "        print('[Error] Element is still not Tag after getting the parent.')\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_self_index(element):\n",
    "    \"\"\"Return the index of the element among its siblings.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    int\n",
    "        \n",
    "    \"\"\"\n",
    "    self_type = element.name\n",
    "    previous_siblings_of_all_types = list(element.previous_siblings)\n",
    "    previous_siblings_of_same_type = [element for element in previous_siblings_of_all_types if element.name == self_type]\n",
    "    return len(previous_siblings_of_same_type) + 1 # css selector starts indexing with 1 instead of 0\n",
    "\n",
    "\n",
    "# Reference: https://stackoverflow.com/a/32263260 (basic structure inspiration)\n",
    "# Reference: https://csswizardry.com/2012/05/keep-your-css-selectors-short (tips to improve efficiency)\n",
    "\n",
    "def describe_part_of_css_selector(node):\n",
    "    \"\"\"Construct part of the css selector path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    enough_to_be_unique = False\n",
    "    \n",
    "    node_type = node.name\n",
    "    \n",
    "    node_attrs = node.attrs\n",
    "    node_attrs_string = ''\n",
    "    for k,v in node_attrs.items():\n",
    "        if k == 'id':\n",
    "            node_attrs_string += '#' + node_attrs[k]\n",
    "            enough_to_be_unique = True\n",
    "            break\n",
    "        elif k == 'class':\n",
    "            node_attrs_string += '.'+'.'.join(node_attrs[k])\n",
    "\n",
    "    element_part = node_type + node_attrs_string\n",
    "            \n",
    "    if not enough_to_be_unique:\n",
    "        length = get_self_index(node)\n",
    "        if (length) > 1:\n",
    "            element_part = '%s:nth-of-type(%s)' % (element_part, length)\n",
    "        \n",
    "    return element_part\n",
    "\n",
    "def get_css_selector_path(node):\n",
    "    \"\"\"Construct the whole css selector path to a certain element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    node: bs4.element\n",
    "        An BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    path = [describe_part_of_css_selector(node)]\n",
    "    for parent in node.parents:\n",
    "        if parent.name == 'body' : # or '#' in path[0], comment out this to get more complete path to facilitate go_up\n",
    "            break\n",
    "        path.insert(0, describe_part_of_css_selector(parent))\n",
    "    return ' > '.join(path)\n",
    "\n",
    "def elevate_css_selector_path(path):\n",
    "    \"\"\"Get the css selector path to the element that is one level above the current element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: string\n",
    "        The css selector path to an BS4 element from the parsed tree.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return '>'.join(path.split('>')[:-1]).strip() if '>' in path else path\n",
    "\n",
    "\n",
    "from collections.abc import Iterable\n",
    "def is_iterable(obj):\n",
    "    \"\"\"Check if the passed object is iterable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obj: object\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    boolean\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return isinstance(obj, Iterable)\n",
    "\n",
    "\n",
    "def flatten_list(l):\n",
    "    \"\"\"Flatten a list of lists to a one-layer list (elements are in original order). Note this is NOT recursive, meaning multi-layered list of lists cannot be converted into a single-layered list in one transformation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    l: list\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def extract_text(element):\n",
    "    \"\"\"Extract the textual content of an element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return element.getText(separator=u'\\n').strip()\n",
    "\n",
    "\n",
    "def get_directly_related_link(element):\n",
    "    \"\"\"Extract the link directly related to the element.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    count = 0\n",
    "    while element.name != 'a' and count < 5:\n",
    "        element = element.parent\n",
    "        count += 1\n",
    "    if element.name != 'a':\n",
    "        return ''\n",
    "    else:\n",
    "        return element.get('href',default='')\n",
    "\n",
    "\n",
    "def get_indirectly_related_links(element):\n",
    "    \"\"\"Extract the links indirectly related to the element (i.e. belonging to the sibling elements).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list of string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    return remove_blank_element_in_list([link.get('href',default='') for link in element.parent.find_all('a')])\n",
    "\n",
    "\n",
    "def get_related_link(element):\n",
    "    \"\"\"Extract the link directly related to the element, if none is found, get indirectly related links.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    element: bs4.element\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string or list of string\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    link = get_directly_related_link(element)\n",
    "    \n",
    "    if link != '':\n",
    "        return link\n",
    "    else:\n",
    "        links = get_indirectly_related_links(element)\n",
    "        if len(links) == 1 and links[0].strip() != '':\n",
    "            return links[0]\n",
    "        else:\n",
    "            return links\n",
    "\n",
    "def get_longest_separator(text):\n",
    "    \"\"\"Return the longest separator (formed by multiple newline) in the text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: string\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    if isinstance(text, str) and '\\n' in text:\n",
    "        return max(re.findall(r'\\n+', text, re.DOTALL), key=lambda x: len(x))\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def get_longest_separator_in_list(texts):\n",
    "    \"\"\"Return the longest separator (formed by multiple newline) in the texts contained in the list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    texts: list of string\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    string\n",
    "        \n",
    "    \"\"\"\n",
    "    return max([get_longest_separator(text) for text in texts], key=len)\n",
    "\n",
    "\n",
    "def remove_blank_element_in_list(li):\n",
    "    \"\"\"Return a cleaned version of the list with all blank elements removed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    li: list\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list\n",
    "        \n",
    "    \"\"\"\n",
    "    return [element for element in li if element.strip()!='']\n",
    "\n",
    "def recursive_split(text):\n",
    "    \"\"\"Return a multi-layer list of lists resulting from a recursive split of the text (split by longer separator first).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: String\n",
    "        A piece of text that contains separators of different lengths.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    list (of lists)\n",
    "        \n",
    "    \"\"\"\n",
    "    longest_separator = get_longest_separator(text)\n",
    "    if longest_separator == '':\n",
    "        return text\n",
    "    else:\n",
    "        return [recursive_split(part) for part in remove_blank_element_in_list(text.split(longest_separator))]\n",
    "    \n",
    "def get_unique_sample_element(soup, target_phrase = '', context_radius = 40):\n",
    "    \"\"\"Find and return an element based on the html structure and a target phrase, solicit additional information from user through input questions if needed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup: bs4.soup\n",
    "        The parsed tree of the response.\n",
    "    target_phrase: string (optional, if not provided, the function will ask user to input)\n",
    "        The phrase used to find the sample element.\n",
    "    context_radius: int (optional, default = 40)\n",
    "        How many characters to display to help user choose recurring phrases based on their contexts.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    bs4.element.Tag\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    attempt_count = 0\n",
    "    matched_elements = []\n",
    "    \n",
    "    if target_phrase != '':\n",
    "        target_phrase = target_phrase.lower()\n",
    "        matched_elements = soup.find_all(text = re.compile(target_phrase,re.IGNORECASE))\n",
    "        attempt_count += 1\n",
    "    \n",
    "    while len(matched_elements)!=1:\n",
    "        \n",
    "        #######################################################################################################\n",
    "        # Situation where matched elements have the same textual content\n",
    "        \n",
    "        if len(set([str(matched_element) for matched_element in matched_elements]))==1:\n",
    "            last_index = -1\n",
    "            phrases_in_context = []\n",
    "            whole_page_text = re.sub('\\s+',' ',soup.text).lower()\n",
    "            \n",
    "            if whole_page_text.count(target_phrase) == len(matched_elements):\n",
    "            \n",
    "                for i in range(whole_page_text.count(target_phrase)):\n",
    "                    current_index = whole_page_text.index(target_phrase,last_index+1)\n",
    "                    phrases_in_context.append(whole_page_text[current_index-context_radius:current_index]+'\\\\\\\\ '+whole_page_text[current_index:current_index+len(target_phrase)]+' //'+whole_page_text[current_index+len(target_phrase):current_index+len(target_phrase)+context_radius])\n",
    "                    last_index = current_index\n",
    "                \n",
    "                if len(set(phrases_in_context))==1:\n",
    "                    print('[Error] There are '+str(len(phrases_in_context))+' occurences of the same target phrase on the page that have very similar contexts.\\nPlease use the browser inspector tool to copy the \"selector\" or \"Selector Path\".\\n')\n",
    "                    return None\n",
    "                else:\n",
    "                    numbered_contexts = ''\n",
    "                    for i in range(len(phrases_in_context)):\n",
    "                        numbered_contexts += 'Choice '+str(i+1)+':  '+phrases_in_context[i] + '\\n'\n",
    "                    print('There are '+str(len(phrases_in_context))+' occurences of the same target phrase on the page,\\nplease choose one based on their contexts:\\n\\n' + numbered_contexts + '\\n')\n",
    "\n",
    "                which_one = 0\n",
    "                while which_one-1 not in range(len(phrases_in_context)):\n",
    "                    which_one = input('Which choice is the element you that want to scrape: [1, 2, 3, ...]\\n')\n",
    "                    try:\n",
    "                        which_one = int(which_one)\n",
    "                    except:\n",
    "                        which_one = 0\n",
    "                matched_elements = [matched_elements[which_one-1]]\n",
    "                \n",
    "            else:\n",
    "                print('[Error] The number of matched elements and the number of target phrase occurences are not the same.\\nPlease use the browser inspector tool to copy the \"selector\" or \"Selector Path\".\\n')\n",
    "                return None\n",
    "            \n",
    "        #######################################################################################################\n",
    "        if attempt_count > 0:\n",
    "            \n",
    "            if len(matched_elements) > 0 and len(matched_elements) < 5:\n",
    "                \n",
    "                numbered_choices = ''\n",
    "                for i in range(len(matched_elements)):\n",
    "                    numbered_choices += '\\tChoice '+str(i+1)+':  '+str(matched_elements[i])[:80]+ '\\n'\n",
    "\n",
    "                print('\\nThere are '+str(len(matched_elements))+' matched elements given your last input. They are:\\n'+numbered_choices)\n",
    "                \n",
    "                # Choose one\n",
    "                which_one = 0\n",
    "                while which_one-1 not in range(len(matched_elements)):\n",
    "                    which_one = input('Which choice is the element you that want to scrape: [1, 2, 3, ...]\\n')\n",
    "                    try:\n",
    "                        which_one = int(which_one)\n",
    "                    except:\n",
    "                        which_one = 0\n",
    "                matched_elements = [matched_elements[which_one-1]]\n",
    "            \n",
    "            else:\n",
    "                if len(matched_elements) > 5:\n",
    "                    print('\\nThere are '+str(len(matched_elements))+' matched elements given your last input. They are:\\n\\n\\t'+'\\n\\t'.join([str(matched_element)[:80] for matched_element in matched_elements[:10]])+'\\n\\nPlease be more specific in your target phrase.\\n')\n",
    "                if len(matched_elements) == 0:\n",
    "                    print('\\nNo match was found, please check for typos in the target phrase (case insensitive) or check if the website is fully collected.')            \n",
    "\n",
    "                # Search again\n",
    "                target_phrase = input('What is the displayed text for one of the elements you want to scrape: '+('(Type \"QUIT\" to stop)' if attempt_count>3 else '')+'\\n')\n",
    "                if target_phrase == 'QUIT':\n",
    "                    print('\\n[Error] It is likely that the website is not fully collected.\\n        Please try this command: get_response_and_save_html(PUT_IN_YOUR_URL)\\n        A HTML file will be created in your local folder, open it with a browser.\\n        If you cannot see what you want to find on the page, please switch to dynamic scraping method.\\n')\n",
    "                    return None\n",
    "                matched_elements = soup.find_all(text = re.compile(target_phrase,re.IGNORECASE))\n",
    "        \n",
    "        # Attempt count increments\n",
    "        attempt_count += 1\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    sample_element = matched_elements[0]\n",
    "    sample_element = elevate_till_is_tag(sample_element)\n",
    "    print('\\nUnique match is found:\\n'+str(sample_element)[:100]+ (' ......' if len(str(sample_element))>100 else '') +'\\n\\n')\n",
    "    \n",
    "    if sample_element.name == 'script':\n",
    "        matched_lines = [line for line in sample_element.prettify().split('\\n') if target_phrase in line.lower()]\n",
    "        try:\n",
    "            assert(len(matched_lines)==1)\n",
    "            matched_line = matched_lines[0].strip().strip(';')\n",
    "            matched_data = matched_line.split('=',maxsplit=1)[1].strip()\n",
    "            data = pd.DataFrame(json.loads(matched_data))\n",
    "            return data\n",
    "        except:\n",
    "            print('[Error] There are multiple occurences of the target phrase in the JS script.\\nPlease use another more unique target phrase or inspect the page source for the data in JS script.\\n')\n",
    "            return None\n",
    "    \n",
    "    return sample_element\n",
    "\n",
    "def extract_contents(soup, path, verbose = True):\n",
    "    \"\"\"Extract and return the texts and links with the target path in the parsed tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    soup: bs4.soup\n",
    "        The parsed tree of the response.\n",
    "    path: string\n",
    "        The css selector path to the target elements.\n",
    "    verbose: boolean (optional, default = True)\n",
    "        Whether or not to print the process message.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if soup is None:\n",
    "        return None\n",
    "    \n",
    "    if isinstance(soup, pd.DataFrame):\n",
    "        return soup\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nExtracting contents ...\\n')\n",
    "    \n",
    "    if path.startswith('HEADER:'):\n",
    "        tables = pd.read_html(str(soup))\n",
    "        target_table = [table for table in tables if str(tuple(table.columns.tolist())) == path.replace('HEADER:','')][0]\n",
    "        return target_table\n",
    "    \n",
    "    target_elements = soup.select(path)\n",
    "\n",
    "    extracted_contents = pd.DataFrame([(recursive_split(extract_text(target_element)), get_related_link(target_element)) for target_element in target_elements], columns = ['text','url'])\n",
    "\n",
    "    return extracted_contents\n",
    "    \n",
    "def scrape_what_from_where(target_phrase, url, go_up = 0):\n",
    "    \"\"\"Get the contents that are similar to the element with phrase \"what\" in the website \"where\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_phrase: string\n",
    "        The displayed text of one of the elements you want to scrape.\n",
    "    url: string\n",
    "        The url of the website you want to scrape.\n",
    "    go_up: int\n",
    "        How many levels to go up in order to get the amount of contents you want.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    response = get_response(url)\n",
    "    \n",
    "    soup = get_soup(response)\n",
    "\n",
    "    # Check if the data is in a table, if so, directly return the table\n",
    "    try:\n",
    "        tables = pd.read_html(str(soup))\n",
    "    except:\n",
    "        tables = []\n",
    "        \n",
    "    print(len(tables))\n",
    "    if len(tables)>0 and (len(set([tuple(table.columns.tolist()) for table in tables])) == len(tables)):        \n",
    "        tables_containing_target_phrase = [table for table in tables if target_phrase in str(table)]\n",
    "        tables_containing_target_phrase = sorted(tables_containing_target_phrase, key=lambda t: len(str(t)))\n",
    "        if len(tables_containing_target_phrase)>0:\n",
    "            while len(tables_containing_target_phrase)>0:\n",
    "                print('\\nThere are '+str(len(tables_containing_target_phrase))+' tables with the target phrase:\\n')\n",
    "                target_table = tables_containing_target_phrase[0]\n",
    "                print(target_table)\n",
    "                is_right_table = input('\\nIs this table what you want to scrape? [Yes/No]\\n')\n",
    "                if is_right_table.lower()[0] == 'y':\n",
    "                    right_header = tuple(target_table.columns.tolist())\n",
    "                    print('\\nThe right header is:\\n\\t'+str(right_header))\n",
    "                    return target_table, 'HEADER:'+str(right_header)\n",
    "                else:    \n",
    "                    tables_containing_target_phrase.pop(0)\n",
    "            if len(tables_containing_target_phrase)==0:\n",
    "                print('\\nThe target data is not one of the tables, moving on to other html elements.\\n')\n",
    "\n",
    "    \n",
    "    # Pinpoint the sample element through dialogue\n",
    "    sample_element = get_unique_sample_element(soup, target_phrase)\n",
    "    if sample_element is None:\n",
    "        return None, ''\n",
    "    if isinstance(sample_element, pd.DataFrame):\n",
    "        print('[Success] Data is in the JS script and now extracted as a DataFrame into the variable \"soup\".\\n')\n",
    "        return sample_element, ''\n",
    "    \n",
    "    # Build the css selector path to the sample element\n",
    "    sample_path = get_css_selector_path(sample_element)\n",
    "        \n",
    "    \n",
    "    # Go up the parse tree if needed:\n",
    "    path = sample_path[:]\n",
    "    for i in range(go_up):\n",
    "        path = elevate_css_selector_path(path)\n",
    "    \n",
    "    # Extract content\n",
    "    extracted_contents = extract_contents(soup, path)\n",
    "    \n",
    "    # If data is extracted from html path instead of from json, print the path for future use\n",
    "    if path != '':\n",
    "        print('\\n[Success] The selector path used to extract contents is:\\n\\n\\t'+path+'\\n')\n",
    "    \n",
    "    return extracted_contents, path\n",
    "\n",
    "\n",
    "def get_response_and_save_html(url,  path = ''):\n",
    "    \"\"\"Get the response of the website and save it as an HTML.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url: string\n",
    "        The url to the website that needs to be scraped. \n",
    "    path: string (optional, default = ./TEMP.html)\n",
    "        The path at which the HTML file will be saved.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    response = get_response(url)\n",
    "    \n",
    "    save_html(response.text, url, path = path)\n",
    "    \n",
    "\n",
    "def create_page_url_list(template_url, start_index, end_index, unique_first_url = None):\n",
    "    page_url_list = []\n",
    "    if unique_first_url is not None:\n",
    "        page_url_list.append(unique_first_url)\n",
    "    for i in range(start_index,end_index+1):\n",
    "        page_url_list.append(template_url.replace('NUMBER',str(i)))\n",
    "    return page_url_list\n",
    "\n",
    "def merge_dataframes(dataframes):\n",
    "    output_dataframe = pd.DataFrame()\n",
    "    for dataframe in dataframes:\n",
    "        output_dataframe = output_dataframe.append(ignore_index = True)\n",
    "    return output_dataframe\n",
    "\n",
    "def extract_path_from_pages(path, pages, save_separately = False, file_path_template = None , reporting_interval = None, verbose = False):\n",
    "\n",
    "    number_of_pages = len(pages)\n",
    "    index_width = len(str(number_of_pages+1))\n",
    "    \n",
    "    if reporting_interval is None:\n",
    "        reporting_interval = int(number_of_pages/10)+1 if number_of_pages<1000 else int(number_of_pages/40)\n",
    "        \n",
    "    output_dataframe = pd.DataFrame()\n",
    "    \n",
    "    for i in range(number_of_pages):\n",
    "        if i % reporting_interval == 0:\n",
    "            print(str(i)+'/'+str(number_of_pages), end=', ')\n",
    "        url = pages[i]\n",
    "        \n",
    "        dataframe = extract_contents(get_soup(get_response(url, verbose = verbose)), path, verbose = verbose)\n",
    "        \n",
    "        if save_separately: \n",
    "            if file_path_template is None:\n",
    "                print('\\n[Error] To save the dataframes from different pages separatorly, you need to provide a file path template.\\n')\n",
    "                return None\n",
    "            file_path = file_path_template.replace('NUMBER', str(i).zfill(index_width))\n",
    "            dataframe.to_csv(file_path, index = False)\n",
    "            \n",
    "        else:\n",
    "            output_dataframe = output_dataframe.append(dataframe, ignore_index=True)\n",
    "    \n",
    "    print('\\n\\n[Success] Content extraction finished.\\n\\n')\n",
    "    \n",
    "    if not save_separately: \n",
    "        return output_dataframe\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_base_url(url):\n",
    "    return url.split('://')[0]+'://'+url.split('://')[1].split('/')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://digitalcollections.nypl.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://digitalcollections.nypl.org\" is collected successfully.\n",
      "0\n",
      "\n",
      "There are 2 matched elements given your last input. They are:\n",
      "\tChoice 1:  The Black Experience in Children's Books: Selections from Augusta Baker's Biblio\n",
      "\tChoice 2:  Children's book illustrations\n",
      "\n",
      "Which choice is the element you that want to scrape: [1, 2, 3, ...]\n",
      "1\n",
      "\n",
      "Unique match is found:\n",
      "<h5>The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies</h5>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv#container > div#home-lanes-main > div#collections > div.lane.inverse > div.lane-items > a.lane-item > h5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies</td>\n",
       "      <td>/collections/the-black-experience-in-childrens-books-selections-from-augusta-bakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scrapbooks of New York City views</td>\n",
       "      <td>/collections/scrapbooks-of-new-york-city-views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li ji ji shi: er shi wu juan</td>\n",
       "      <td>/collections/li-ji-ji-shi-er-shi-wu-juan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women of distinction: remarkable in works and invincible in character</td>\n",
       "      <td>/collections/women-of-distinction-remarkable-in-works-and-invincible-in-character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Collection of ledgers and cash books covering the period 1891-1925</td>\n",
       "      <td>/collections/collection-of-ledgers-and-cash-books-covering-the-period-1891-1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>William Blake: Illuminated Books</td>\n",
       "      <td>/collections/william-blake-illuminated-books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Ise Monogatari Emaki</td>\n",
       "      <td>/collections/ise-monogatari-emaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Des cleres et nobles femmes</td>\n",
       "      <td>/collections/des-cleres-et-nobles-femmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Minchô shiken (The Colored Inkstone of the Ming Period)</td>\n",
       "      <td>/collections/minch-shiken-the-colored-inkstone-of-the-ming-period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Tsuki hyakushi</td>\n",
       "      <td>/collections/tsuki-hyakushi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         text  \\\n",
       "0    The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies   \n",
       "1                                                           Scrapbooks of New York City views   \n",
       "2                                                                Li ji ji shi: er shi wu juan   \n",
       "3                       Women of distinction: remarkable in works and invincible in character   \n",
       "4                          Collection of ledgers and cash books covering the period 1891-1925   \n",
       "..                                                                                        ...   \n",
       "225                                                          William Blake: Illuminated Books   \n",
       "226                                                                      Ise Monogatari Emaki   \n",
       "227                                                               Des cleres et nobles femmes   \n",
       "228                                   Minchô shiken (The Colored Inkstone of the Ming Period)   \n",
       "229                                                                            Tsuki hyakushi   \n",
       "\n",
       "                                                                                     url  \n",
       "0    /collections/the-black-experience-in-childrens-books-selections-from-augusta-bakers  \n",
       "1                                         /collections/scrapbooks-of-new-york-city-views  \n",
       "2                                               /collections/li-ji-ji-shi-er-shi-wu-juan  \n",
       "3      /collections/women-of-distinction-remarkable-in-works-and-invincible-in-character  \n",
       "4        /collections/collection-of-ledgers-and-cash-books-covering-the-period-1891-1925  \n",
       "..                                                                                   ...  \n",
       "225                                         /collections/william-blake-illuminated-books  \n",
       "226                                                    /collections/ise-monogatari-emaki  \n",
       "227                                             /collections/des-cleres-et-nobles-femmes  \n",
       "228                    /collections/minch-shiken-the-colored-inkstone-of-the-ming-period  \n",
       "229                                                          /collections/tsuki-hyakushi  \n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"Children's Book\", \"https://digitalcollections.nypl.org\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://digitalcollections.nypl.org\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<h5>The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies</h5>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv#container > div#home-lanes-main > div#collections > div.lane.inverse > div.lane-items > a.lane-item\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies, 303 items]</td>\n",
       "      <td>/collections/the-black-experience-in-childrens-books-selections-from-augusta-bakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Scrapbooks of New York City views, 3,141 items]</td>\n",
       "      <td>/collections/scrapbooks-of-new-york-city-views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Li ji ji shi: er shi wu juan, 26 items]</td>\n",
       "      <td>/collections/li-ji-ji-shi-er-shi-wu-juan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Women of distinction: remarkable in works and invincible in character, 49 items]</td>\n",
       "      <td>/collections/women-of-distinction-remarkable-in-works-and-invincible-in-character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Collection of ledgers and cash books covering the period 1891-1925, 15 items]</td>\n",
       "      <td>/collections/collection-of-ledgers-and-cash-books-covering-the-period-1891-1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>[William Blake: Illuminated Books, 89 items]</td>\n",
       "      <td>/collections/william-blake-illuminated-books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>[Ise Monogatari Emaki , 109 items]</td>\n",
       "      <td>/collections/ise-monogatari-emaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>[Des cleres et nobles femmes, 78 items]</td>\n",
       "      <td>/collections/des-cleres-et-nobles-femmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>[Minchô shiken (The Colored Inkstone of the Ming Period), 65 items]</td>\n",
       "      <td>/collections/minch-shiken-the-colored-inkstone-of-the-ming-period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>[Tsuki hyakushi , 56 items]</td>\n",
       "      <td>/collections/tsuki-hyakushi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0    [The Black Experience in Children's Books: Selections from Augusta Baker's Bibliographies, 303 items]   \n",
       "1                                                         [Scrapbooks of New York City views, 3,141 items]   \n",
       "2                                                                 [Li ji ji shi: er shi wu juan, 26 items]   \n",
       "3                        [Women of distinction: remarkable in works and invincible in character, 49 items]   \n",
       "4                           [Collection of ledgers and cash books covering the period 1891-1925, 15 items]   \n",
       "..                                                                                                     ...   \n",
       "225                                                           [William Blake: Illuminated Books, 89 items]   \n",
       "226                                                                     [Ise Monogatari Emaki , 109 items]   \n",
       "227                                                                [Des cleres et nobles femmes, 78 items]   \n",
       "228                                    [Minchô shiken (The Colored Inkstone of the Ming Period), 65 items]   \n",
       "229                                                                            [Tsuki hyakushi , 56 items]   \n",
       "\n",
       "                                                                                     url  \n",
       "0    /collections/the-black-experience-in-childrens-books-selections-from-augusta-bakers  \n",
       "1                                         /collections/scrapbooks-of-new-york-city-views  \n",
       "2                                               /collections/li-ji-ji-shi-er-shi-wu-juan  \n",
       "3      /collections/women-of-distinction-remarkable-in-works-and-invincible-in-character  \n",
       "4        /collections/collection-of-ledgers-and-cash-books-covering-the-period-1891-1925  \n",
       "..                                                                                   ...  \n",
       "225                                         /collections/william-blake-illuminated-books  \n",
       "226                                                    /collections/ise-monogatari-emaki  \n",
       "227                                             /collections/des-cleres-et-nobles-femmes  \n",
       "228                    /collections/minch-shiken-the-colored-inkstone-of-the-ming-period  \n",
       "229                                                          /collections/tsuki-hyakushi  \n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"The Black Experience in Children's Books\",\"https://digitalcollections.nypl.org\", go_up = 1)\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://digitalcollections.nypl.org/collections/changing-new-york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://digitalcollections.nypl.org/collections/changing-new-york\" is collected successfully.\n",
      "0\n",
      "\n",
      "There are 3 matched elements given your last input. They are:\n",
      "\tChoice 1:  Broome Street no. 512-514, Ma…\n",
      "\tChoice 2:  Broadway near Broome Street, …\n",
      "\tChoice 3:  Broome Street, Nos. 504-506, …\n",
      "\n",
      "Which choice is the element you that want to scrape: [1, 2, 3, ...]\n",
      "first\n",
      "Which choice is the element you that want to scrape: [1, 2, 3, ...]\n",
      "1\n",
      "\n",
      "Unique match is found:\n",
      "<a alt=\"Broome Street no. 512-514, Manhattan\" class=\"title\" href=\"/items/510d47d9-4fbc-a3d9-e040-e00 ......\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv#container > div#collection > div#collection-right > div.results-wrapper > div#results-list-wrapper > ul#results-list > li > div.description:nth-of-type(2) > a.title\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Broome Street no. 512-514, Ma…</td>\n",
       "      <td>/items/510d47d9-4fbc-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamport Export Company, 507-5…</td>\n",
       "      <td>/items/510d47d9-4fbd-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Broadway near Broome Street, …</td>\n",
       "      <td>/items/510d47d9-4fb9-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broome Street, Nos. 504-506, …</td>\n",
       "      <td>/items/510d47d9-4fbb-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First Avenue and East 70th St…</td>\n",
       "      <td>/items/510d47d9-4f4e-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ewen Avenue No. 2565 (Bar and…</td>\n",
       "      <td>/items/510d47d9-4ecb-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gas tank and Queensboro Bridg…</td>\n",
       "      <td>/items/510d47d9-4f4b-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vanderbilt, From E. 46th Stre…</td>\n",
       "      <td>/items/510d47d9-4f42-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Country Store: interior, Ewen…</td>\n",
       "      <td>/items/510d47d9-4f7d-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Palisade Avenue No. 2505, Spu…</td>\n",
       "      <td>/items/510d47d9-4f0b-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Newsstand, 32nd Street and Th…</td>\n",
       "      <td>/items/510d47d9-4f7e-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Spring and Varick Streets, Ma…</td>\n",
       "      <td>/items/510d47d9-4fba-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oak and New Chambers Streets,…</td>\n",
       "      <td>/items/510d47d9-4f7f-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Grove Street, No. 45, Manhatt…</td>\n",
       "      <td>/items/510d47d9-4edf-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jefferson Market Court, south…</td>\n",
       "      <td>/items/510d47d9-4efc-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>St. Lukes Chapel, 483 Hudson …</td>\n",
       "      <td>/items/510d47d9-4fc4-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tri-boro Barber School, 264 B…</td>\n",
       "      <td>/items/510d47d9-4fc0-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Blossom Restaurant, 103 Bower…</td>\n",
       "      <td>/items/510d47d9-4f80-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mulberry and Prince Streets, …</td>\n",
       "      <td>/items/510d47d9-4fbe-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Waterfront, South Street, Man…</td>\n",
       "      <td>/items/510d47d9-4f0d-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Unemployed and huts, West Hou…</td>\n",
       "      <td>/items/510d47d9-4fc2-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Huts and unemployed, West Hou…</td>\n",
       "      <td>/items/510d47d9-4fc1-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Huts and unemployed, West Hou…</td>\n",
       "      <td>/items/510d47d9-4f81-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Murray Hill Hotel, from Park …</td>\n",
       "      <td>/items/510d47d9-4f3e-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Murray Hill Hotel, Manhattan.</td>\n",
       "      <td>/items/510d47d9-4f3d-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Murray Hill Hotel, Manhattan.</td>\n",
       "      <td>/items/510d47d9-4f3b-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Murray Hill Hotel, 112 Park A…</td>\n",
       "      <td>/items/510d47d9-4f3c-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Minetta Street, Nos. 2, 4, 6,…</td>\n",
       "      <td>/items/510d47d9-4f1a-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Squibb Building with Sherry N…</td>\n",
       "      <td>/items/510d47d9-4f46-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Daily News Building, 42nd Str…</td>\n",
       "      <td>/items/510d47d9-4f3f-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mori's Restaurant, 144 Bleeck…</td>\n",
       "      <td>/items/510d47d9-4fbf-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gramercy Park, west side look…</td>\n",
       "      <td>/items/510d47d9-4f26-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Henry Street, Manhattan.</td>\n",
       "      <td>/items/510d47d9-4fb3-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cliff and Ferry Street, Manha…</td>\n",
       "      <td>/items/510d47d9-4f82-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fish Market, South Street, Ma…</td>\n",
       "      <td>/items/510d47d9-4f0e-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fulton Street Dock, Manhattan…</td>\n",
       "      <td>/items/510d47d9-4ef7-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gramercy Park, nos. 3-5, Manh…</td>\n",
       "      <td>/items/510d47d9-4f25-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Seventh Avenue looking south …</td>\n",
       "      <td>/items/510d47d9-4f83-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40th Street between Fifth and…</td>\n",
       "      <td>/items/510d47d9-4edc-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40th Street between Fifth and…</td>\n",
       "      <td>/items/510d47d9-4f38-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40th Street between Sixth and…</td>\n",
       "      <td>/items/510d47d9-4f39-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>40th Street between Sixth and…</td>\n",
       "      <td>/items/510d47d9-4f3a-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gasoline Station, Tenth Avenu…</td>\n",
       "      <td>/items/510d47d9-4f2d-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ferry, West 23rd Street, Manh…</td>\n",
       "      <td>/items/510d47d9-4f0f-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Oldest apartment house in New…</td>\n",
       "      <td>/items/510d47d9-4f10-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Gus Hills Minstrels, 1890-189…</td>\n",
       "      <td>/items/510d47d9-4f11-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Firehouse, Park Avenue and Ea…</td>\n",
       "      <td>/items/510d47d9-4f12-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>George Washington Bridge, Riv…</td>\n",
       "      <td>/items/510d47d9-4eb1-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>El' station, Sixth and Ninth …</td>\n",
       "      <td>/items/510d47d9-4f84-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Whelan's Drug Store, 44th Str…</td>\n",
       "      <td>/items/510d47d9-4f41-a3d9-e040-e00a18064a99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text  \\\n",
       "0   Broome Street no. 512-514, Ma…   \n",
       "1   Lamport Export Company, 507-5…   \n",
       "2   Broadway near Broome Street, …   \n",
       "3   Broome Street, Nos. 504-506, …   \n",
       "4   First Avenue and East 70th St…   \n",
       "5   Ewen Avenue No. 2565 (Bar and…   \n",
       "6   Gas tank and Queensboro Bridg…   \n",
       "7   Vanderbilt, From E. 46th Stre…   \n",
       "8   Country Store: interior, Ewen…   \n",
       "9   Palisade Avenue No. 2505, Spu…   \n",
       "10  Newsstand, 32nd Street and Th…   \n",
       "11  Spring and Varick Streets, Ma…   \n",
       "12  Oak and New Chambers Streets,…   \n",
       "13  Grove Street, No. 45, Manhatt…   \n",
       "14  Jefferson Market Court, south…   \n",
       "15  St. Lukes Chapel, 483 Hudson …   \n",
       "16  Tri-boro Barber School, 264 B…   \n",
       "17  Blossom Restaurant, 103 Bower…   \n",
       "18  Mulberry and Prince Streets, …   \n",
       "19  Waterfront, South Street, Man…   \n",
       "20  Unemployed and huts, West Hou…   \n",
       "21  Huts and unemployed, West Hou…   \n",
       "22  Huts and unemployed, West Hou…   \n",
       "23  Murray Hill Hotel, from Park …   \n",
       "24   Murray Hill Hotel, Manhattan.   \n",
       "25   Murray Hill Hotel, Manhattan.   \n",
       "26  Murray Hill Hotel, 112 Park A…   \n",
       "27  Minetta Street, Nos. 2, 4, 6,…   \n",
       "28  Squibb Building with Sherry N…   \n",
       "29  Daily News Building, 42nd Str…   \n",
       "30  Mori's Restaurant, 144 Bleeck…   \n",
       "31  Gramercy Park, west side look…   \n",
       "32        Henry Street, Manhattan.   \n",
       "33  Cliff and Ferry Street, Manha…   \n",
       "34  Fish Market, South Street, Ma…   \n",
       "35  Fulton Street Dock, Manhattan…   \n",
       "36  Gramercy Park, nos. 3-5, Manh…   \n",
       "37  Seventh Avenue looking south …   \n",
       "38  40th Street between Fifth and…   \n",
       "39  40th Street between Fifth and…   \n",
       "40  40th Street between Sixth and…   \n",
       "41  40th Street between Sixth and…   \n",
       "42  Gasoline Station, Tenth Avenu…   \n",
       "43  Ferry, West 23rd Street, Manh…   \n",
       "44  Oldest apartment house in New…   \n",
       "45  Gus Hills Minstrels, 1890-189…   \n",
       "46  Firehouse, Park Avenue and Ea…   \n",
       "47  George Washington Bridge, Riv…   \n",
       "48  El' station, Sixth and Ninth …   \n",
       "49  Whelan's Drug Store, 44th Str…   \n",
       "\n",
       "                                            url  \n",
       "0   /items/510d47d9-4fbc-a3d9-e040-e00a18064a99  \n",
       "1   /items/510d47d9-4fbd-a3d9-e040-e00a18064a99  \n",
       "2   /items/510d47d9-4fb9-a3d9-e040-e00a18064a99  \n",
       "3   /items/510d47d9-4fbb-a3d9-e040-e00a18064a99  \n",
       "4   /items/510d47d9-4f4e-a3d9-e040-e00a18064a99  \n",
       "5   /items/510d47d9-4ecb-a3d9-e040-e00a18064a99  \n",
       "6   /items/510d47d9-4f4b-a3d9-e040-e00a18064a99  \n",
       "7   /items/510d47d9-4f42-a3d9-e040-e00a18064a99  \n",
       "8   /items/510d47d9-4f7d-a3d9-e040-e00a18064a99  \n",
       "9   /items/510d47d9-4f0b-a3d9-e040-e00a18064a99  \n",
       "10  /items/510d47d9-4f7e-a3d9-e040-e00a18064a99  \n",
       "11  /items/510d47d9-4fba-a3d9-e040-e00a18064a99  \n",
       "12  /items/510d47d9-4f7f-a3d9-e040-e00a18064a99  \n",
       "13  /items/510d47d9-4edf-a3d9-e040-e00a18064a99  \n",
       "14  /items/510d47d9-4efc-a3d9-e040-e00a18064a99  \n",
       "15  /items/510d47d9-4fc4-a3d9-e040-e00a18064a99  \n",
       "16  /items/510d47d9-4fc0-a3d9-e040-e00a18064a99  \n",
       "17  /items/510d47d9-4f80-a3d9-e040-e00a18064a99  \n",
       "18  /items/510d47d9-4fbe-a3d9-e040-e00a18064a99  \n",
       "19  /items/510d47d9-4f0d-a3d9-e040-e00a18064a99  \n",
       "20  /items/510d47d9-4fc2-a3d9-e040-e00a18064a99  \n",
       "21  /items/510d47d9-4fc1-a3d9-e040-e00a18064a99  \n",
       "22  /items/510d47d9-4f81-a3d9-e040-e00a18064a99  \n",
       "23  /items/510d47d9-4f3e-a3d9-e040-e00a18064a99  \n",
       "24  /items/510d47d9-4f3d-a3d9-e040-e00a18064a99  \n",
       "25  /items/510d47d9-4f3b-a3d9-e040-e00a18064a99  \n",
       "26  /items/510d47d9-4f3c-a3d9-e040-e00a18064a99  \n",
       "27  /items/510d47d9-4f1a-a3d9-e040-e00a18064a99  \n",
       "28  /items/510d47d9-4f46-a3d9-e040-e00a18064a99  \n",
       "29  /items/510d47d9-4f3f-a3d9-e040-e00a18064a99  \n",
       "30  /items/510d47d9-4fbf-a3d9-e040-e00a18064a99  \n",
       "31  /items/510d47d9-4f26-a3d9-e040-e00a18064a99  \n",
       "32  /items/510d47d9-4fb3-a3d9-e040-e00a18064a99  \n",
       "33  /items/510d47d9-4f82-a3d9-e040-e00a18064a99  \n",
       "34  /items/510d47d9-4f0e-a3d9-e040-e00a18064a99  \n",
       "35  /items/510d47d9-4ef7-a3d9-e040-e00a18064a99  \n",
       "36  /items/510d47d9-4f25-a3d9-e040-e00a18064a99  \n",
       "37  /items/510d47d9-4f83-a3d9-e040-e00a18064a99  \n",
       "38  /items/510d47d9-4edc-a3d9-e040-e00a18064a99  \n",
       "39  /items/510d47d9-4f38-a3d9-e040-e00a18064a99  \n",
       "40  /items/510d47d9-4f39-a3d9-e040-e00a18064a99  \n",
       "41  /items/510d47d9-4f3a-a3d9-e040-e00a18064a99  \n",
       "42  /items/510d47d9-4f2d-a3d9-e040-e00a18064a99  \n",
       "43  /items/510d47d9-4f0f-a3d9-e040-e00a18064a99  \n",
       "44  /items/510d47d9-4f10-a3d9-e040-e00a18064a99  \n",
       "45  /items/510d47d9-4f11-a3d9-e040-e00a18064a99  \n",
       "46  /items/510d47d9-4f12-a3d9-e040-e00a18064a99  \n",
       "47  /items/510d47d9-4eb1-a3d9-e040-e00a18064a99  \n",
       "48  /items/510d47d9-4f84-a3d9-e040-e00a18064a99  \n",
       "49  /items/510d47d9-4f41-a3d9-e040-e00a18064a99  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"broome street\", \"https://digitalcollections.nypl.org/collections/changing-new-york\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://digitalcollections.nypl.org/collections/changing-new-york\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<script type=\"text/javascript\">\n",
      "\n",
      "  var search_results = [{\"restricted\":false,\"item\":{\"id\":\"510d47d9- ......\n",
      "\n",
      "\n",
      "[Success] Data is in the JS script and now extracted as a DataFrame into the variable \"soup\".\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restricted</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f9d-a3d9-e040-e00a18064a99', 'title': 'Rope store, South Street and James Slip, Manhattan.', 'image_id': '482824', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/T2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f4a-a3d9-e040-e00a18064a99', 'title': 'Automat, 977 Eighth Avenue, Manhattan.', 'image_id': '482752', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/sAeaJhzFT5-wk6k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f85-a3d9-e040-e00a18064a99', 'title': 'Columbus Circle, Manhattan.', 'image_id': '482580', 'multi': True, 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/6b_qtKEqTYC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f00-a3d9-e040-e00a18064a99', 'title': 'Broadway and Thomas Street, Manhattan.', 'image_id': '482689', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/BBYhX4MbQXSp1S9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f13-a3d9-e040-e00a18064a99', 'title': 'Broadway and Thomas Street, Manhattan.', 'image_id': '482706', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/fgkkXRSHSruvd-Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4eb0-a3d9-e040-e00a18064a99', 'title': 'Columbia Presbyterian Medical Center, 168th Street and Broadway, from 165th Street and Riverside Drive, Manhattan.', 'image_id': '482622', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f02-a3d9-e040-e00a18064a99', 'title': 'Gay Street no. 14-16, Manhattan.', 'image_id': '482690', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/0-YF-9etQLOSL4VBoVjFJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47df-335a-a3d9-e040-e00a18064a99', 'title': 'Riverside Drive, no. 857, at 159th Street, Manhattan.', 'image_id': '1219146', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f6f-a3d9-e040-e00a18064a99', 'title': 'George Washington Bridge, Riverside Drive and 179th Street, Manhattan.', 'image_id': '482785', 'sequence_number': 1, 'high_res_link': 'http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': '510d47d9-4f20-a3d9-e040-e00a18064a99', 'title': 'Salmagundi Club, 47 Fifth Avenue, Manhattan', 'image_id': '482716', 'multi': True, 'sequence_number': 1, 'high_res_link': 'http://link.nypl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     restricted  \\\n",
       "0         False   \n",
       "1         False   \n",
       "2         False   \n",
       "3         False   \n",
       "4         False   \n",
       "..          ...   \n",
       "195       False   \n",
       "196       False   \n",
       "197       False   \n",
       "198       False   \n",
       "199       False   \n",
       "\n",
       "                                                                                                                                                                                                        item  \n",
       "0    {'id': '510d47d9-4f9d-a3d9-e040-e00a18064a99', 'title': 'Rope store, South Street and James Slip, Manhattan.', 'image_id': '482824', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/T2...  \n",
       "1    {'id': '510d47d9-4f4a-a3d9-e040-e00a18064a99', 'title': 'Automat, 977 Eighth Avenue, Manhattan.', 'image_id': '482752', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/sAeaJhzFT5-wk6k...  \n",
       "2    {'id': '510d47d9-4f85-a3d9-e040-e00a18064a99', 'title': 'Columbus Circle, Manhattan.', 'image_id': '482580', 'multi': True, 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/6b_qtKEqTYC...  \n",
       "3    {'id': '510d47d9-4f00-a3d9-e040-e00a18064a99', 'title': 'Broadway and Thomas Street, Manhattan.', 'image_id': '482689', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/BBYhX4MbQXSp1S9...  \n",
       "4    {'id': '510d47d9-4f13-a3d9-e040-e00a18064a99', 'title': 'Broadway and Thomas Street, Manhattan.', 'image_id': '482706', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/fgkkXRSHSruvd-Y...  \n",
       "..                                                                                                                                                                                                       ...  \n",
       "195  {'id': '510d47d9-4eb0-a3d9-e040-e00a18064a99', 'title': 'Columbia Presbyterian Medical Center, 168th Street and Broadway, from 165th Street and Riverside Drive, Manhattan.', 'image_id': '482622', ...  \n",
       "196  {'id': '510d47d9-4f02-a3d9-e040-e00a18064a99', 'title': 'Gay Street no. 14-16, Manhattan.', 'image_id': '482690', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org/0-YF-9etQLOSL4VBoVjFJ...  \n",
       "197  {'id': '510d47df-335a-a3d9-e040-e00a18064a99', 'title': 'Riverside Drive, no. 857, at 159th Street, Manhattan.', 'image_id': '1219146', 'sequence_number': 1, 'high_res_link': 'http://link.nypl.org...  \n",
       "198  {'id': '510d47d9-4f6f-a3d9-e040-e00a18064a99', 'title': 'George Washington Bridge, Riverside Drive and 179th Street, Manhattan.', 'image_id': '482785', 'sequence_number': 1, 'high_res_link': 'http...  \n",
       "199  {'id': '510d47d9-4f20-a3d9-e040-e00a18064a99', 'title': 'Salmagundi Club, 47 Fifth Avenue, Manhattan', 'image_id': '482716', 'multi': True, 'sequence_number': 1, 'high_res_link': 'http://link.nypl...  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"Salmagundi Club\", \"https://digitalcollections.nypl.org/collections/changing-new-york\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.aqistudy.cn/historydata/monthdata.php?city=%E4%B8%8A%E6%B5%B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://www.aqistudy.cn/historydata/monthdata.php?city=%E4%B8%8A%E6%B5%B7\" is collected successfully.\n",
      "1\n",
      "\n",
      "No match was found, please check for typos in the target phrase (case insensitive) or check if the website is fully collected.\n",
      "What is the displayed text for one of the elements you want to scrape: \n",
      "120\n",
      "\n",
      "No match was found, please check for typos in the target phrase (case insensitive) or check if the website is fully collected.\n",
      "What is the displayed text for one of the elements you want to scrape: \n",
      "121\n",
      "\n",
      "No match was found, please check for typos in the target phrase (case insensitive) or check if the website is fully collected.\n",
      "What is the displayed text for one of the elements you want to scrape: \n",
      "159\n",
      "\n",
      "No match was found, please check for typos in the target phrase (case insensitive) or check if the website is fully collected.\n",
      "What is the displayed text for one of the elements you want to scrape: (Type \"QUIT\" to stop)\n",
      "QUIT\n",
      "\n",
      "[Error] It is likely that the website is not fully collected.\n",
      "        Please try this command: get_response_and_save_html(PUT_IN_YOUR_URL)\n",
      "        A HTML file will be created in your local folder, open it with a browser.\n",
      "        If you cannot see what you want to find on the page, please switch to dynamic scraping method.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"2013-12\", \"https://www.aqistudy.cn/historydata/monthdata.php?city=%E4%B8%8A%E6%B5%B7\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://www.aqistudy.cn/historydata/monthdata.php?city=%E4%B8%8A%E6%B5%B7\" is collected successfully.\n",
      "[Success] The HTML file is saved succesfully.\n"
     ]
    }
   ],
   "source": [
    "get_response_and_save_html(\"https://www.aqistudy.cn/historydata/monthdata.php?city=%E4%B8%8A%E6%B5%B7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index.html\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<h1>清上海书业商团旗帜</h1>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv.mar-w1170:nth-of-type(4) > div.mar-w1170:nth-of-type(2) > div.act1wp.clearfix.act2con#result_list > div.act2con-div.margin-t28 > div.act1-con.fl:nth-of-type(3) > h1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>清上海书业商团旗帜</td>\n",
       "      <td>/historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>民国徐汇公学教具--徐汇中学捐赠</td>\n",
       "      <td>/historymuseum/historymuseum/dc/myyp/2019/12/18/3419955b6e5e35b7016f17d0fb000572.html?tm=1579785391841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1934年上海徐家汇土山湾铸铜钟</td>\n",
       "      <td>/historymuseum/historymuseum/dc/myyp/2019/11/19/3419955b6e5e35b7016e8165260d01b8.html?tm=1579785391841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1907年外白渡桥落成铭牌</td>\n",
       "      <td>/historymuseum/historymuseum/dc/myyp/2019/10/16/3419955b6dc7fb5a016dd2e36ae000fd.html?tm=1579785391841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               text  \\\n",
       "0         清上海书业商团旗帜   \n",
       "1  民国徐汇公学教具--徐汇中学捐赠   \n",
       "2  1934年上海徐家汇土山湾铸铜钟   \n",
       "3     1907年外白渡桥落成铭牌   \n",
       "\n",
       "                                                                                                      url  \n",
       "0  /historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841  \n",
       "1  /historymuseum/historymuseum/dc/myyp/2019/12/18/3419955b6e5e35b7016f17d0fb000572.html?tm=1579785391841  \n",
       "2  /historymuseum/historymuseum/dc/myyp/2019/11/19/3419955b6e5e35b7016e8165260d01b8.html?tm=1579785391841  \n",
       "3  /historymuseum/historymuseum/dc/myyp/2019/10/16/3419955b6dc7fb5a016dd2e36ae000fd.html?tm=1579785391841  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"清上海书业商\", \"http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index.html\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagination Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = create_page_url_list(template_url = 'http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index_NUMBER.html?tm=1579785391762', start_index = 1, end_index = 4, unique_first_url = 'http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5, 1/5, 2/5, 3/5, 4/5, \n",
      "\n",
      "[Success] Content extraction finished.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = extract_path_from_pages(path, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = get_base_url('http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/index_NUMBER.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url'] = base_url + df['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_pages = df['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<span style=\"font-family:宋体; font-size:10.5pt\">商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。</span>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv.mar-w1170:nth-of-type(4) > div.class-dinfowp.clearfix:nth-of-type(2) > div.class-dinfo-right.fl:nth-of-type(2) > p > span:nth-of-type(2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text url\n",
       "0  商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。  []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841'\n",
    "extracted_contents, info_path = scrape_what_from_where('革命期间发挥了', url)\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<span style=\"font-family:宋体; font-size:10.5pt\">商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。</span>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv.mar-w1170:nth-of-type(4) > div.class-dinfowp.clearfix:nth-of-type(2) > div.class-dinfo-right.fl:nth-of-type(2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[清上海书业商团旗帜, 尺寸： 长160厘米，宽114厘米, 简介, [商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。, 1886, 年朱槐庐等人创立上海书业崇德公所，, 1905, 年重组为“上海书业公所”，不久组织成立上海书业商团。在上海光复之役中，书业商团参与了恢复上海全境、攻打制造局的战斗。胜利后，商团全体人员不分昼夜，认真巡逻、保境安民。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   text  \\\n",
       "0  [清上海书业商团旗帜, 尺寸： 长160厘米，宽114厘米, 简介, [商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。, 1886, 年朱槐庐等人创立上海书业崇德公所，, 1905, 年重组为“上海书业公所”，不久组织成立上海书业商团。在上海光复之役中，书业商团参与了恢复上海全境、攻打制造局的战斗。胜利后，商团全体人员不分昼夜，认真巡逻、保境安民。], 进入高清播放器]   \n",
       "\n",
       "                                                                                                     url  \n",
       "0  [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.shh-shrhmuseum.org.cn/historymuseum/historymuseum/dc/myyp/2020/01/23/3419955b6e5e35b7016fd28a7f890c42.html?tm=1579785391841'\n",
    "extracted_contents, info_path = scrape_what_from_where('革命期间发挥了', url, go_up = 2)\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = 'div.mar-w1170:nth-of-type(4) > div.class-dinfowp.clearfix:nth-of-type(2) > div.class-dinfo-right.fl:nth-of-type(2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/17, 2/17, 4/17, 6/17, 8/17, 10/17, 12/17, 14/17, 16/17, \n",
      "\n",
      "[Success] Content extraction finished.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info_df = extract_path_from_pages(info_path, info_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[清上海书业商团旗帜, 尺寸： 长160厘米，宽114厘米, 简介, [商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。, 1886, 年朱槐庐等人创立上海书业崇德公所，, 1905, 年重组为“上海书业公所”，不久组织成立上海书业商团。在上海光复之役中，书业商团参与了恢复上海全境、攻打制造局的战斗。胜利后，商团全体人员不分昼夜，认真巡逻、保境安民。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[民国徐汇公学教具--徐汇中学捐赠, 尺寸： 透镜：底部直径11厘米，高35厘米。, 简介, 透镜：底部直径11厘米，高35厘米。三棱镜：底部直径9.5厘米，宽14厘米，高33厘米。蒸汽机模型：长39厘米，宽29厘米，高53厘米。三球仪：长55厘米，宽25厘米，高41厘米。徐汇公学创办于1850年，是天主教在上海开办最早的洋学堂，是中国最早按西洋办学模式设立的学校之一。初名圣依纳爵公学，吸...</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1934年上海徐家汇土山湾铸铜钟, 尺寸： 直径39厘米，高43厘米, 简介, [土山湾孤儿院成立于, 1864, 年，其前身为天主教士薛孔昭所设横塘育婴堂，专收教外孤儿，衣之食之，并教以工艺美术诸艺，以便长大后能有一技谋生。孤儿院内部设木工、五金、印书等工场，此教堂铜钟即为该院五金部作品，钟面人像为“圣女小德肋撒”，也即“圣女小德兰”。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1907年外白渡桥落成铭牌, 尺寸： 纵40厘米，横52厘米, 简介, [ 1856, 年，威尔斯公司在苏州河黄浦江交汇处建造了木结构的“威尔斯桥”。, 1875, 年工部局强行收购该桥并出资重建，建成后不再收过桥费。因其临近外滩花园，遂称“花园桥”（又称外摆渡桥或外白渡桥）。随着近代交通的迅速发展，, 1906, 年工部局拆除原木结构旧桥重建为钢桥，翌年落成，为上海第一座近代化的钢桁架...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[民国 文魁斋“天晓得”招牌, 尺寸： 长84厘米，宽121厘米，厚3.8厘米, 简介, 民国初年，在广西路汉口路先后开设了两家糖食店，都取名“文魁斋”。为了争夺生意，两家都指责对方是冒牌，其中一家甚至定制了一块奇特的牌子，上有一只乌龟，指责“东首假冒”，假冒者是乌龟。当时，大舞台正门在汉口路上，正对着这两家“文魁斋”，所以就流传出一句歇后语，凡是不知究竟的事，就说“大舞台对过——天晓得”...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[民国正广和汽水, 尺寸： 底部直径7.5厘米，高29.5厘米, 简介, [正广和洋行总部设在英国伦敦，, 1874, 年开始在上海、香港等地开设分公司，, 1892, 年创建上海泌乐水厂，专事生产汽水、蒸馏水、餐用矿泉水、苏打水、姜汁水、柠檬水，广受欢迎，销路很好。, 20, 世纪, 20, 年代新厂建成投产，改称正广和汽水，是中国最早的汽水饮料生产厂。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[近代亚细亚火油公司壳牌中文铜牌, 尺寸： 直径74厘米，高100厘米, 简介, [过去中国的石油主要依赖进口，统称为“洋油”。, 1903, 年，原为竞争对手的壳牌运输贸易有限公司与荷兰皇家石油公司在伦敦成立亚细亚火油公司。, 1908, 年，在上海成立办事处。, 1917, 年公司入驻位于今中山东一路, 1, 号高七层的亚细亚大楼，人称“外滩第一楼”。这块亚细亚火油公司壳牌中文铜牌原本...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[清咸丰六年 郁森盛、经正记、王永盛银饼一组, 尺寸： 直径4厘米, 简介, [郁森盛、经正记、王永盛作为清代上海最大的沙船号商，从事沿海运输，对上海港区的形成和上海城市发展做出了巨大贡献。同时，他们还开设钱庄，于咸丰六年（, 1856, ）铸造并发行了银饼，金融街称之为“上海银饼”，开创了沪上商号自铸银元流通市场的先例，也是中国现存最早以“两”为单位的银元，为清末上海经济发展作出了贡献。...</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[近代上海美租界界碑, 尺寸： 长76.5厘米，宽68.5厘米，厚3厘米, 简介, [上海开埠后，美国传教士在虹口地区广置地皮，拓展势力。在造成既成事实后，要求上海道台划定该区域为美国租界。, 1863, 年，英美租界正式合并，称为洋泾浜北首外人租界或英美公共租界。, 1893, 年, 6, 月，上海道台与工部局划定美租界新界址并树立界石，此碑可能为当时遗物。上海开埠后，美国传教士在虹口地...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[清乾隆四十五年陆锡熊父母诰命, 尺寸： 纵21厘米，横350厘米, 简介, [该诰命系乾隆四十五年（, 1780, ）朝廷封赠陆锡熊父母的文书。诰命质地为五色织锦，朵朵祥云点缀其间，雍容华贵，由满汉文合璧书写，并合于中轴，在满汉文结尾处均钤盖“制诰之宝”，是清代荣典制度的重要例证，亦是反映明清上海地区人文昌盛的重要实物。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[清吴之璠作竹雕寒山拾得图笔筒, 尺寸： 口沿直径10.5厘米，高14.5厘米, 简介, 嘉定竹刻始于明朝，至清代，嘉定县已成为竹刻工艺的中心之一。嘉定派竹人以笔法运刀法，勇于创新，所刻制的人物、山水、草虫、禽鸟，刀法精湛，精妙绝伦，具有新鲜灵动之感。此竹雕笔筒为清代嘉定竹刻名家吴之璠所作，刻绘的是寒山与拾得两位隐僧泛舟渡海的生动场景。, 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[元代铁锭榫, 尺寸： 长22厘米，宽13厘米，厚3厘米, 简介, [普陀区志丹苑元代水闸遗址出土。铁锭榫又称为腰榫，束腰铁锭，元宝铁等，用作石料的联接构件，以加固石板，防止石板错缝移位。考古人员在上海元代水闸遗址发现，水闸底石的青石板间镶嵌了密密麻麻的铁锭榫共约, 400, 只，可见这项水利工程规模之大，工艺之考究。], 进入高清播放器]</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[向导, 尺寸： 纵25.7厘米，横18.5厘米，厚1厘米, 简介, [中国共产党中央第一个政治机关报。, 1922, 年, 9, 月, 13, 日创刊于上海。周报。, 1927, 年, 7, 月, 18, 日出至第, 201, 期停刊。蔡和森等先后主编。该报设有“中国一周”“世界一周”“时事评论”“读者之声”等栏目，系统地阐述了中共关于反帝反封建的民主革命纲领，阐明了建立以国共合作为中心...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[民国 黄兴行书轴, 尺寸： 纵173厘米，横44.5厘米, 简介, [1912, 年，清帝宣布退位，统治中国, 2000, 多年的封建王朝土崩瓦解，革命的为之奋斗多年的目标终于实现，举国欢迎鼓舞。但同时，南京留守政府撤销，袁世凯在北京宣誓就任临时大总统。黄兴在寓居上海期间写下此诗“冯夷击鼓走夷门，铜马西来风雨昏。此地信陵曾养士，只今谁解救王孙”，表达自己心情。其中，“此地信陵曾养士，只今...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1911年民国总统当选人斗方, 尺寸： 纵61.5厘米，横90厘米, 简介, [1911, 年, 12, 月, 29, 日，辛亥革命后已宣布独立的各省代表在南京召开临时大总统选举大会。到会的, 17, 省代表共计, 40, 余人，孙中山身在上海，未出席。袁希洛以江苏省代表身份赴会并任书记员，负责选票记录。选举结果，孙中山得, 16, 票，黄兴得, 1, 票，孙中山当选为临时大总统。会后，...</td>\n",
       "      <td>[javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1895年  道白生公司制造的清花机, 尺寸： 长520厘米，宽225厘米，高155厘米, 简介, [清花是棉纺织厂的第一道工序，后面还有梳棉、并条、粗纱、细纱、络筒、捻线等多道工序。此清花机由道白生（, Dobson and Barlow, ）公司制造，原为三新纺织厂所有，, 1931, 年为申新公司购得。三新厂前身为清末洋务运动时所开设的上海机器织布局，俗称“洋布局”，为中国最早的官...</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[清 振远将军铜炮, 尺寸： 长312厘米，口径32.8厘米，后径43.5厘米，宽68厘米, 简介, [第一次鸦片战争前后，清政府在各战略要地加强军备建设。吴淞口为江苏省战略要地。清政府曾在此添置大炮多门。此为, 1841, 年提督江南全省军门陈化成等督造，并安装在吴淞炮台的一门大炮。该炮, 1984, 年, 11, 月，由上海边防检查站在吴淞炮台遗址附近施工时发现，为鸦片战争期间吴淞战役...</td>\n",
       "      <td>[javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&amp;collection=1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       text  \\\n",
       "0      [清上海书业商团旗帜, 尺寸： 长160厘米，宽114厘米, 简介, [商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。, 1886, 年朱槐庐等人创立上海书业崇德公所，, 1905, 年重组为“上海书业公所”，不久组织成立上海书业商团。在上海光复之役中，书业商团参与了恢复上海全境、攻打制造局的战斗。胜利后，商团全体人员不分昼夜，认真巡逻、保境安民。], 进入高清播放器]   \n",
       "1   [民国徐汇公学教具--徐汇中学捐赠, 尺寸： 透镜：底部直径11厘米，高35厘米。, 简介, 透镜：底部直径11厘米，高35厘米。三棱镜：底部直径9.5厘米，宽14厘米，高33厘米。蒸汽机模型：长39厘米，宽29厘米，高53厘米。三球仪：长55厘米，宽25厘米，高41厘米。徐汇公学创办于1850年，是天主教在上海开办最早的洋学堂，是中国最早按西洋办学模式设立的学校之一。初名圣依纳爵公学，吸...   \n",
       "2                    [1934年上海徐家汇土山湾铸铜钟, 尺寸： 直径39厘米，高43厘米, 简介, [土山湾孤儿院成立于, 1864, 年，其前身为天主教士薛孔昭所设横塘育婴堂，专收教外孤儿，衣之食之，并教以工艺美术诸艺，以便长大后能有一技谋生。孤儿院内部设木工、五金、印书等工场，此教堂铜钟即为该院五金部作品，钟面人像为“圣女小德肋撒”，也即“圣女小德兰”。], 进入高清播放器]   \n",
       "3   [1907年外白渡桥落成铭牌, 尺寸： 纵40厘米，横52厘米, 简介, [ 1856, 年，威尔斯公司在苏州河黄浦江交汇处建造了木结构的“威尔斯桥”。, 1875, 年工部局强行收购该桥并出资重建，建成后不再收过桥费。因其临近外滩花园，遂称“花园桥”（又称外摆渡桥或外白渡桥）。随着近代交通的迅速发展，, 1906, 年工部局拆除原木结构旧桥重建为钢桥，翌年落成，为上海第一座近代化的钢桁架...   \n",
       "4   [民国 文魁斋“天晓得”招牌, 尺寸： 长84厘米，宽121厘米，厚3.8厘米, 简介, 民国初年，在广西路汉口路先后开设了两家糖食店，都取名“文魁斋”。为了争夺生意，两家都指责对方是冒牌，其中一家甚至定制了一块奇特的牌子，上有一只乌龟，指责“东首假冒”，假冒者是乌龟。当时，大舞台正门在汉口路上，正对着这两家“文魁斋”，所以就流传出一句歇后语，凡是不知究竟的事，就说“大舞台对过——天晓得”...   \n",
       "5            [民国正广和汽水, 尺寸： 底部直径7.5厘米，高29.5厘米, 简介, [正广和洋行总部设在英国伦敦，, 1874, 年开始在上海、香港等地开设分公司，, 1892, 年创建上海泌乐水厂，专事生产汽水、蒸馏水、餐用矿泉水、苏打水、姜汁水、柠檬水，广受欢迎，销路很好。, 20, 世纪, 20, 年代新厂建成投产，改称正广和汽水，是中国最早的汽水饮料生产厂。], 进入高清播放器]   \n",
       "6   [近代亚细亚火油公司壳牌中文铜牌, 尺寸： 直径74厘米，高100厘米, 简介, [过去中国的石油主要依赖进口，统称为“洋油”。, 1903, 年，原为竞争对手的壳牌运输贸易有限公司与荷兰皇家石油公司在伦敦成立亚细亚火油公司。, 1908, 年，在上海成立办事处。, 1917, 年公司入驻位于今中山东一路, 1, 号高七层的亚细亚大楼，人称“外滩第一楼”。这块亚细亚火油公司壳牌中文铜牌原本...   \n",
       "7   [清咸丰六年 郁森盛、经正记、王永盛银饼一组, 尺寸： 直径4厘米, 简介, [郁森盛、经正记、王永盛作为清代上海最大的沙船号商，从事沿海运输，对上海港区的形成和上海城市发展做出了巨大贡献。同时，他们还开设钱庄，于咸丰六年（, 1856, ）铸造并发行了银饼，金融街称之为“上海银饼”，开创了沪上商号自铸银元流通市场的先例，也是中国现存最早以“两”为单位的银元，为清末上海经济发展作出了贡献。...   \n",
       "8   [近代上海美租界界碑, 尺寸： 长76.5厘米，宽68.5厘米，厚3厘米, 简介, [上海开埠后，美国传教士在虹口地区广置地皮，拓展势力。在造成既成事实后，要求上海道台划定该区域为美国租界。, 1863, 年，英美租界正式合并，称为洋泾浜北首外人租界或英美公共租界。, 1893, 年, 6, 月，上海道台与工部局划定美租界新界址并树立界石，此碑可能为当时遗物。上海开埠后，美国传教士在虹口地...   \n",
       "9                             [清乾隆四十五年陆锡熊父母诰命, 尺寸： 纵21厘米，横350厘米, 简介, [该诰命系乾隆四十五年（, 1780, ）朝廷封赠陆锡熊父母的文书。诰命质地为五色织锦，朵朵祥云点缀其间，雍容华贵，由满汉文合璧书写，并合于中轴，在满汉文结尾处均钤盖“制诰之宝”，是清代荣典制度的重要例证，亦是反映明清上海地区人文昌盛的重要实物。], 进入高清播放器]   \n",
       "10                      [清吴之璠作竹雕寒山拾得图笔筒, 尺寸： 口沿直径10.5厘米，高14.5厘米, 简介, 嘉定竹刻始于明朝，至清代，嘉定县已成为竹刻工艺的中心之一。嘉定派竹人以笔法运刀法，勇于创新，所刻制的人物、山水、草虫、禽鸟，刀法精湛，精妙绝伦，具有新鲜灵动之感。此竹雕笔筒为清代嘉定竹刻名家吴之璠所作，刻绘的是寒山与拾得两位隐僧泛舟渡海的生动场景。, 进入高清播放器]   \n",
       "11                              [元代铁锭榫, 尺寸： 长22厘米，宽13厘米，厚3厘米, 简介, [普陀区志丹苑元代水闸遗址出土。铁锭榫又称为腰榫，束腰铁锭，元宝铁等，用作石料的联接构件，以加固石板，防止石板错缝移位。考古人员在上海元代水闸遗址发现，水闸底石的青石板间镶嵌了密密麻麻的铁锭榫共约, 400, 只，可见这项水利工程规模之大，工艺之考究。], 进入高清播放器]   \n",
       "12  [向导, 尺寸： 纵25.7厘米，横18.5厘米，厚1厘米, 简介, [中国共产党中央第一个政治机关报。, 1922, 年, 9, 月, 13, 日创刊于上海。周报。, 1927, 年, 7, 月, 18, 日出至第, 201, 期停刊。蔡和森等先后主编。该报设有“中国一周”“世界一周”“时事评论”“读者之声”等栏目，系统地阐述了中共关于反帝反封建的民主革命纲领，阐明了建立以国共合作为中心...   \n",
       "13  [民国 黄兴行书轴, 尺寸： 纵173厘米，横44.5厘米, 简介, [1912, 年，清帝宣布退位，统治中国, 2000, 多年的封建王朝土崩瓦解，革命的为之奋斗多年的目标终于实现，举国欢迎鼓舞。但同时，南京留守政府撤销，袁世凯在北京宣誓就任临时大总统。黄兴在寓居上海期间写下此诗“冯夷击鼓走夷门，铜马西来风雨昏。此地信陵曾养士，只今谁解救王孙”，表达自己心情。其中，“此地信陵曾养士，只今...   \n",
       "14  [1911年民国总统当选人斗方, 尺寸： 纵61.5厘米，横90厘米, 简介, [1911, 年, 12, 月, 29, 日，辛亥革命后已宣布独立的各省代表在南京召开临时大总统选举大会。到会的, 17, 省代表共计, 40, 余人，孙中山身在上海，未出席。袁希洛以江苏省代表身份赴会并任书记员，负责选票记录。选举结果，孙中山得, 16, 票，黄兴得, 1, 票，孙中山当选为临时大总统。会后，...   \n",
       "15  [1895年  道白生公司制造的清花机, 尺寸： 长520厘米，宽225厘米，高155厘米, 简介, [清花是棉纺织厂的第一道工序，后面还有梳棉、并条、粗纱、细纱、络筒、捻线等多道工序。此清花机由道白生（, Dobson and Barlow, ）公司制造，原为三新纺织厂所有，, 1931, 年为申新公司购得。三新厂前身为清末洋务运动时所开设的上海机器织布局，俗称“洋布局”，为中国最早的官...   \n",
       "16  [清 振远将军铜炮, 尺寸： 长312厘米，口径32.8厘米，后径43.5厘米，宽68厘米, 简介, [第一次鸦片战争前后，清政府在各战略要地加强军备建设。吴淞口为江苏省战略要地。清政府曾在此添置大炮多门。此为, 1841, 年提督江南全省军门陈化成等督造，并安装在吴淞炮台的一门大炮。该炮, 1984, 年, 11, 月，由上海边防检查站在吴淞炮台遗址附近施工时发现，为鸦片战争期间吴淞战役...   \n",
       "\n",
       "                                                                                                                                                                                                        url  \n",
       "0                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "1                                             [javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "2                                                                         [javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "3                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "4                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "5                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "6                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "7                 [javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "8                                                                                                     [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "9   [javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseu...  \n",
       "10                                                                        [javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "11                                                                                                    [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "12                                                                                                    [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "13                                                                                                    [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "14                                                                                                    [javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "15                                                                        [javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  \n",
       "16                                            [javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, javascript:;, /historymuseum/historymuseum/myyp_big.html?#branch=dc_myyp&collection=1]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['清上海书业商团旗帜',\n",
       " '尺寸： 长160厘米，宽114厘米',\n",
       " '简介',\n",
       " ['商团是清末上海商界的自卫武装团体，在辛亥革命期间发挥了重要的作用。',\n",
       "  '1886',\n",
       "  '年朱槐庐等人创立上海书业崇德公所，',\n",
       "  '1905',\n",
       "  '年重组为“上海书业公所”，不久组织成立上海书业商团。在上海光复之役中，书业商团参与了恢复上海全境、攻打制造局的战斗。胜利后，商团全体人员不分昼夜，认真巡逻、保境安民。'],\n",
       " '进入高清播放器']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://fund.eastmoney.com/fund.html#os_0;isall_0;ft_;pt_1\" is collected successfully.\n",
      "3\n",
      "\n",
      "There are 1 tables with the target phrase:\n",
      "\n",
      "     关注  比较   序号    基金代码                 基金简称 2021-02-10         2021-02-09  \\\n",
      "     关注  比较   序号    基金代码                 基金简称       单位净值    累计净值       单位净值   \n",
      "0   NaN NaN    1    8438      九泰行业优选混合C估值图基金吧     1.4024  1.4024     1.2246   \n",
      "1   NaN NaN    2    8437      九泰行业优选混合A估值图基金吧     1.4022  1.4022     1.2244   \n",
      "2   NaN NaN    3  161725  招商中证白酒指数(LOF)估值图基金吧     1.6198  3.2509     1.5439   \n",
      "3   NaN NaN    4    3190    创金合信消费主题股票A估值图基金吧     3.4247  3.2593     3.2655   \n",
      "4   NaN NaN    5    3191    创金合信消费主题股票C估值图基金吧     3.3633  3.1756     3.2071   \n",
      "..   ..  ..  ...     ...                  ...        ...     ...        ...   \n",
      "195 NaN NaN  196    9854      中加优势企业混合C估值图基金吧     1.4617  1.4617     1.4141   \n",
      "196 NaN NaN  197    8277     财通资管行业精选混合估值图基金吧     1.4006  1.4006     1.3550   \n",
      "197 NaN NaN  198    1382      易方达国企改革混合估值图基金吧     2.9200  2.9200     2.8250   \n",
      "198 NaN NaN  199     609        华商新量化混合估值图基金吧     3.0580  3.6080     2.9590   \n",
      "199 NaN NaN  200    6796       富国消费升级混合估值图基金吧     2.7821  2.7821     2.6920   \n",
      "\n",
      "               日增长值    日增长率 申购状态 赎回状态    手续费  \n",
      "       累计净值    日增长值    日增长率 申购状态 赎回状态    手续费  \n",
      "0    1.2246  0.1778  14.52%  限大额   开放  0.00%  \n",
      "1    1.2244  0.1778  14.52%  限大额   开放  0.15%  \n",
      "2    3.1750  0.0759   4.92%   开放   开放  0.10%  \n",
      "3    3.1078  0.1592   4.88%   开放   开放  0.15%  \n",
      "4    3.0281  0.1562   4.87%   开放   开放  0.00%  \n",
      "..      ...     ...     ...  ...  ...    ...  \n",
      "195  1.4141  0.0476   3.37%   暂停   暂停  0.00%  \n",
      "196  1.3550  0.0456   3.37%   开放   开放  0.15%  \n",
      "197  2.8250  0.0950   3.36%   开放   开放  0.15%  \n",
      "198  3.5090  0.0990   3.35%   开放   开放  0.15%  \n",
      "199  2.6920  0.0901   3.35%   开放   开放  0.15%  \n",
      "\n",
      "[200 rows x 14 columns]\n",
      "\n",
      "Is this table what you want to scrape? [Yes/No]\n",
      "Yes\n",
      "\n",
      "The right header is:\n",
      "\t(('关注', '关注'), ('比较', '比较'), ('序号', '序号'), ('基金代码', '基金代码'), ('基金简称', '基金简称'), ('2021-02-10', '单位净值'), ('2021-02-10', '累计净值'), ('2021-02-09', '单位净值'), ('2021-02-09', '累计净值'), ('日增长值', '日增长值'), ('日增长率', '日增长率'), ('申购状态', '申购状态'), ('赎回状态', '赎回状态'), ('手续费', '手续费'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>关注</th>\n",
       "      <th>比较</th>\n",
       "      <th>序号</th>\n",
       "      <th>基金代码</th>\n",
       "      <th>基金简称</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2021-02-10</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2021-02-09</th>\n",
       "      <th>日增长值</th>\n",
       "      <th>日增长率</th>\n",
       "      <th>申购状态</th>\n",
       "      <th>赎回状态</th>\n",
       "      <th>手续费</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>关注</th>\n",
       "      <th>比较</th>\n",
       "      <th>序号</th>\n",
       "      <th>基金代码</th>\n",
       "      <th>基金简称</th>\n",
       "      <th>单位净值</th>\n",
       "      <th>累计净值</th>\n",
       "      <th>单位净值</th>\n",
       "      <th>累计净值</th>\n",
       "      <th>日增长值</th>\n",
       "      <th>日增长率</th>\n",
       "      <th>申购状态</th>\n",
       "      <th>赎回状态</th>\n",
       "      <th>手续费</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8438</td>\n",
       "      <td>九泰行业优选混合C估值图基金吧</td>\n",
       "      <td>1.4024</td>\n",
       "      <td>1.4024</td>\n",
       "      <td>1.2246</td>\n",
       "      <td>1.2246</td>\n",
       "      <td>0.1778</td>\n",
       "      <td>14.52%</td>\n",
       "      <td>限大额</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>8437</td>\n",
       "      <td>九泰行业优选混合A估值图基金吧</td>\n",
       "      <td>1.4022</td>\n",
       "      <td>1.4022</td>\n",
       "      <td>1.2244</td>\n",
       "      <td>1.2244</td>\n",
       "      <td>0.1778</td>\n",
       "      <td>14.52%</td>\n",
       "      <td>限大额</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>161725</td>\n",
       "      <td>招商中证白酒指数(LOF)估值图基金吧</td>\n",
       "      <td>1.6198</td>\n",
       "      <td>3.2509</td>\n",
       "      <td>1.5439</td>\n",
       "      <td>3.1750</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>4.92%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3190</td>\n",
       "      <td>创金合信消费主题股票A估值图基金吧</td>\n",
       "      <td>3.4247</td>\n",
       "      <td>3.2593</td>\n",
       "      <td>3.2655</td>\n",
       "      <td>3.1078</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>4.88%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3191</td>\n",
       "      <td>创金合信消费主题股票C估值图基金吧</td>\n",
       "      <td>3.3633</td>\n",
       "      <td>3.1756</td>\n",
       "      <td>3.2071</td>\n",
       "      <td>3.0281</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>9854</td>\n",
       "      <td>中加优势企业混合C估值图基金吧</td>\n",
       "      <td>1.4617</td>\n",
       "      <td>1.4617</td>\n",
       "      <td>1.4141</td>\n",
       "      <td>1.4141</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>3.37%</td>\n",
       "      <td>暂停</td>\n",
       "      <td>暂停</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197</td>\n",
       "      <td>8277</td>\n",
       "      <td>财通资管行业精选混合估值图基金吧</td>\n",
       "      <td>1.4006</td>\n",
       "      <td>1.4006</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>3.37%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>1382</td>\n",
       "      <td>易方达国企改革混合估值图基金吧</td>\n",
       "      <td>2.9200</td>\n",
       "      <td>2.9200</td>\n",
       "      <td>2.8250</td>\n",
       "      <td>2.8250</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>3.36%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>609</td>\n",
       "      <td>华商新量化混合估值图基金吧</td>\n",
       "      <td>3.0580</td>\n",
       "      <td>3.6080</td>\n",
       "      <td>2.9590</td>\n",
       "      <td>3.5090</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>3.35%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>6796</td>\n",
       "      <td>富国消费升级混合估值图基金吧</td>\n",
       "      <td>2.7821</td>\n",
       "      <td>2.7821</td>\n",
       "      <td>2.6920</td>\n",
       "      <td>2.6920</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>3.35%</td>\n",
       "      <td>开放</td>\n",
       "      <td>开放</td>\n",
       "      <td>0.15%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     关注  比较   序号    基金代码                 基金简称 2021-02-10         2021-02-09  \\\n",
       "     关注  比较   序号    基金代码                 基金简称       单位净值    累计净值       单位净值   \n",
       "0   NaN NaN    1    8438      九泰行业优选混合C估值图基金吧     1.4024  1.4024     1.2246   \n",
       "1   NaN NaN    2    8437      九泰行业优选混合A估值图基金吧     1.4022  1.4022     1.2244   \n",
       "2   NaN NaN    3  161725  招商中证白酒指数(LOF)估值图基金吧     1.6198  3.2509     1.5439   \n",
       "3   NaN NaN    4    3190    创金合信消费主题股票A估值图基金吧     3.4247  3.2593     3.2655   \n",
       "4   NaN NaN    5    3191    创金合信消费主题股票C估值图基金吧     3.3633  3.1756     3.2071   \n",
       "..   ..  ..  ...     ...                  ...        ...     ...        ...   \n",
       "195 NaN NaN  196    9854      中加优势企业混合C估值图基金吧     1.4617  1.4617     1.4141   \n",
       "196 NaN NaN  197    8277     财通资管行业精选混合估值图基金吧     1.4006  1.4006     1.3550   \n",
       "197 NaN NaN  198    1382      易方达国企改革混合估值图基金吧     2.9200  2.9200     2.8250   \n",
       "198 NaN NaN  199     609        华商新量化混合估值图基金吧     3.0580  3.6080     2.9590   \n",
       "199 NaN NaN  200    6796       富国消费升级混合估值图基金吧     2.7821  2.7821     2.6920   \n",
       "\n",
       "               日增长值    日增长率 申购状态 赎回状态    手续费  \n",
       "       累计净值    日增长值    日增长率 申购状态 赎回状态    手续费  \n",
       "0    1.2246  0.1778  14.52%  限大额   开放  0.00%  \n",
       "1    1.2244  0.1778  14.52%  限大额   开放  0.15%  \n",
       "2    3.1750  0.0759   4.92%   开放   开放  0.10%  \n",
       "3    3.1078  0.1592   4.88%   开放   开放  0.15%  \n",
       "4    3.0281  0.1562   4.87%   开放   开放  0.00%  \n",
       "..      ...     ...     ...  ...  ...    ...  \n",
       "195  1.4141  0.0476   3.37%   暂停   暂停  0.00%  \n",
       "196  1.3550  0.0456   3.37%   开放   开放  0.15%  \n",
       "197  2.8250  0.0950   3.36%   开放   开放  0.15%  \n",
       "198  3.5090  0.0990   3.35%   开放   开放  0.15%  \n",
       "199  2.6920  0.0901   3.35%   开放   开放  0.15%  \n",
       "\n",
       "[200 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, info_path = scrape_what_from_where(\"限大额\", \"http://fund.eastmoney.com/fund.html#os_0;isall_0;ft_;pt_1\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nyc.com/arts__attractions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://www.nyc.com/arts__attractions/\" is collected successfully.\n",
      "0\n",
      "\n",
      "There are 3 matched elements given your last input. They are:\n",
      "\tChoice 1:  Central Park\n",
      "\tChoice 2:  New York's \"flagship\" park of 843 acres, 26,000 trees, and almost 9,000 benches \n",
      "\tChoice 3:  Seven and a half miles of Beach on the Atlantic Ocean. Lifeguards are stationed \n",
      "\n",
      "Which choice is the element you that want to scrape: [1, 2, 3, ...]\n",
      "1\n",
      "\n",
      "Unique match is found:\n",
      "<h2>Central Park</h2>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tsection.tiles.tiles_2.container:nth-of-type(4) > div.row.tilesrow > article.lazy.cgreen.col-xs-12.col-sm-6.col-md-4 > header > h2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central Park</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cooper-Hewitt, National Design Museum</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis Island Museum</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Museum of Contemporary Art</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outdoor Movie Guide</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Restaurant Week</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text url\n",
       "0                           Central Park  []\n",
       "1  Cooper-Hewitt, National Design Museum  []\n",
       "2                    Ellis Island Museum  []\n",
       "3         New Museum of Contemporary Art  []\n",
       "4                    Outdoor Movie Guide  []\n",
       "5                        Restaurant Week  []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"Central Park\", \"https://www.nyc.com/arts__attractions/\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://search.huochepiao.com/chezhan/shanghai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://search.huochepiao.com/chezhan/shanghai\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<a href=\"/shike_shanghai_nanjing\">上海 - 南京</a>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\ttable#sys-notice-box > tr > td > table:nth-of-type(2) > tr > td > table > tr > td > a\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>上海 - 南京</td>\n",
       "      <td>/shike_shanghai_nanjing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>上海 - 北京</td>\n",
       "      <td>/shike_shanghai_beijing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上海 - 苏州</td>\n",
       "      <td>/shike_shanghai_suzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>上海 - 杭州</td>\n",
       "      <td>/shike_shanghai_hangzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>上海 - 郑州</td>\n",
       "      <td>/shike_shanghai_zhengzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>上海 - 成都</td>\n",
       "      <td>/shike_shanghai_chengdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>上海 - 天津</td>\n",
       "      <td>/shike_shanghai_tianjin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>上海 - 广州</td>\n",
       "      <td>/shike_shanghai_guangzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>上海 - 合肥</td>\n",
       "      <td>/shike_shanghai_hefei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>上海 - 无锡</td>\n",
       "      <td>/shike_shanghai_wuxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>上海 - 西安</td>\n",
       "      <td>/shike_shanghai_xian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>上海 - 济南</td>\n",
       "      <td>/shike_shanghai_jinan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>上海 - 宁波</td>\n",
       "      <td>/shike_shanghai_ningbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>上海 - 武汉</td>\n",
       "      <td>/shike_shanghai_wuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>上海 - 常州</td>\n",
       "      <td>/shike_shanghai_changzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>上海 - 深圳</td>\n",
       "      <td>/shike_shanghai_shenzhen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>上海 - 厦门</td>\n",
       "      <td>/shike_shanghai_xiamen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>上海 - 南昌</td>\n",
       "      <td>/shike_shanghai_nanchang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>上海 - 徐州</td>\n",
       "      <td>/shike_shanghai_xuzhou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>上海 - 青岛</td>\n",
       "      <td>/shike_shanghai_qingdao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                        url\n",
       "0   上海 - 南京    /shike_shanghai_nanjing\n",
       "1   上海 - 北京    /shike_shanghai_beijing\n",
       "2   上海 - 苏州     /shike_shanghai_suzhou\n",
       "3   上海 - 杭州   /shike_shanghai_hangzhou\n",
       "4   上海 - 郑州  /shike_shanghai_zhengzhou\n",
       "5   上海 - 成都    /shike_shanghai_chengdu\n",
       "6   上海 - 天津    /shike_shanghai_tianjin\n",
       "7   上海 - 广州  /shike_shanghai_guangzhou\n",
       "8   上海 - 合肥      /shike_shanghai_hefei\n",
       "9   上海 - 无锡       /shike_shanghai_wuxi\n",
       "10  上海 - 西安       /shike_shanghai_xian\n",
       "11  上海 - 济南      /shike_shanghai_jinan\n",
       "12  上海 - 宁波     /shike_shanghai_ningbo\n",
       "13  上海 - 武汉      /shike_shanghai_wuhan\n",
       "14  上海 - 常州  /shike_shanghai_changzhou\n",
       "15  上海 - 深圳   /shike_shanghai_shenzhen\n",
       "16  上海 - 厦门     /shike_shanghai_xiamen\n",
       "17  上海 - 南昌   /shike_shanghai_nanchang\n",
       "18  上海 - 徐州     /shike_shanghai_xuzhou\n",
       "19  上海 - 青岛    /shike_shanghai_qingdao"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where(\"上海 - 南京\", \"http://search.huochepiao.com/chezhan/shanghai\")\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = get_base_url(\"http://search.huochepiao.com/chezhan/shanghai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_contents['url'] = base_url + extracted_contents['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = extracted_contents['url'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"http://search.huochepiao.com/shike_shanghai_nanjing\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<a href=\"/checi/G4824/G4825\">G4824/G4825</a>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\ttable:nth-of-type(2) > tr > td > table > tr > td:nth-of-type(2) > table:nth-of-type(2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 南京南, 01:58, 0分, 295, 134.5, 229.5, 0/0/0, 0/0, 50|10|1]], [G9376/G9377, [上海, 00:58, 南京南, 02:29, 1小时31分, 311...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 南京南, 01:58, 0分, 295, 134.5, 229.5, 0/0/0, 0/0, 50|10|1]], [G9376/G9377, [上海, 00:58, 南京南, 02:29, 1小时31分, 311...   \n",
       "\n",
       "                                                                                                                                                                                                       url  \n",
       "0  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where('G4824', pages[0], go_up = 3)\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "车次 出发站 开车时间 到达站 到达时间 用时 里程 硬座 软座 硬卧上/中/下 软卧上/下\n",
      "\n",
      "G4824/G4825 上海虹桥 00:50 南京南 01:58 0分 295 134.5 229.5 0/0/0 0/0 50|10|1\n",
      "G9376/G9377 上海虹桥 00:50 南京南 01:58 0分 295 134.5 229.5 0/0/0 0/0 50|10|1\n",
      "K5550/K5551 上海虹桥 00:50 南京南 01:58 0分 295 134.5 229.5 0/0/0 0/0 50|10|1\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(extracted_contents.text[0][0]))\n",
    "print()\n",
    "print(extracted_contents.text[0][1][0] + ' ' + ' '.join(extracted_contents.text[0][1][1]))\n",
    "print(extracted_contents.text[0][2][0] + ' ' + ' '.join(extracted_contents.text[0][1][1]))\n",
    "print(extracted_contents.text[0][3][0] + ' ' + ' '.join(extracted_contents.text[0][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20, 3/20, 6/20, 9/20, 12/20, 15/20, 18/20, \n",
      "\n",
      "[Success] Content extraction finished.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_schedule_df = extract_path_from_pages(path, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 南京南, 01:58, 0分, 295, 134.5, 229.5, 0/0/0, 0/0, 50|10|1]], [G9376/G9377, [上海, 00:58, 南京南, 02:29, 1小时31分, 311...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G102, [上海虹桥, 06:26, 北京南, 12:29, 6小时3分, 1318, 606, 971, 0/0/0, 0/0, 386|10|1]], [G104, [上海虹桥, 06:37, 北京南, 12:33, 5小时56分, 1318, 606, 971...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8C%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G102, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 苏州, 02:14, 1小时3分, 84, 7, -, 41/65.5/68.5, 90.5/96.5, 71|8|1]], [K5550/K5551, [上海, 01:11, 苏州, 02:14, 1小时3分, 84...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E8%8B%8F%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4571, [上海虹桥, 00:38, 杭州东, 01:23, 45分, 159, 73, 117, 0/0/0, 0/0, 38|10|1]], [K4085, [上海南, 01:02, 杭州东, 02:52, 1小时50分, 167, 24.5, -, 70.5...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%9D%AD%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/G4571, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4110/G4111, [上海虹桥, 01:12, 郑州东, 05:20, 4小时8分, 986, 482.5, 784.5, 0/0/0, 0/0, 72|10|1]], [K4168/K4169, [上海, 01:45, 郑州, 16:18, 14小时33分, ...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E9%83%91%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4110/G4111, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K4085, [上海南, 01:02, 成都, 13:15, 36小时13分, 2473, 263.5, -, 446.5/462.5/477.5, 704.5/735.5, 62|8|1]], [K4616/K4617, [上海, 03:40, 成都, 11:50,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%88%90%E9%83%BD, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K4085, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海南, http://search.huoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G108, [上海虹桥, 07:22, 天津南, 12:45, 5小时23分, 1196, 551, 881, 0/0/0, 0/0, 442|10|1]], [G1229/G1232, [上海虹桥, 07:34, 天津西, 13:45, 6小时11分, 1213, ...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%A4%A9%E6%B4%A5, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G108, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G85, [上海虹桥, 08:00, 广州南, 14:51, 6小时51分, 1790, 793, 1302.5, 0/0/0, 0/0, 480|10|1]], [G1301, [上海虹桥, 10:24, 广州南, 19:02, 8小时38分, 1790, 793,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%B9%BF%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G85, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 合肥南, 03:04, 0分, 468, 202.5, 335, 0/0/0, 0/0, 50|10|1]], [D4678/D4679, [上海虹桥, 01:17, 合肥南, 03:31, 2小时14分, 468...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%90%88%E8%82%A5, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 无锡, 02:47, 1小时36分, 126, 10.5, -, 65.5/70.5/73.5, 99.5/105.5, 71|8|1]], [K5550/K5551, [上海, 01:11, 无锡, 02:47, 1...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%97%A0%E9%94%A1, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K4028/K4025, [上海, 02:06, 西安, 23:48, 21小时42分, 1509, 180.5, -, 310.5/321.5/331.5, 488.5/509.5, 126|8|1]], [G4056/G4057, [上海虹桥, 02:16, 西安...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E8%A5%BF%E5%AE%89, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K4028/K4025, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4282/G4283, [上海虹桥, 05:45, 济南西, 09:48, 4小时3分, 912, 398.5, 673.5, 0/0/0, 0/0, 345|10|1]], [G456/G457, [上海虹桥, 06:05, 济南, 10:36, 4小时31分, ...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%B5%8E%E5%8D%97, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4282/G4283, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K335/K338, [上海南, 05:02, 宁波, 09:38, 4小时36分, 332, -, -, 0/0/0, 0/0, 302|8|2]], [G7541, [上海虹桥, 06:00, 宁波, 07:50, 1小时50分, 314, 144, 237, 0...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%AE%81%E6%B3%A2, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K335/K338, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海南, http://search....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 武汉, 04:45, 0分, 807, 301, 425.5, 0/0/0, 0/0, 50|10|1]], [G4828/G4829, [上海虹桥, 01:46, 武汉, 05:28, 3小时42分, 807, ...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%AD%A6%E6%B1%89, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 常州, 03:19, 2小时8分, 165, 24.5, -, 70.5/75.5/78.5, 108.5/114.5, 71|8|1]], [K4168/K4169, [上海, 01:45, 常州, 03:53, 2...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%B8%B8%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [D2287, [上海虹桥, 07:02, 深圳北, 18:25, 11小时23分, 1892, 481, 597, 0/0/0, 0/0, 422|10|1]], [D377, [上海虹桥, 07:46, 深圳北, 19:25, 11小时39分, 1623, 568,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%B7%B1%E5%9C%B3, #, #, #, #, #, #, #, #, #, #, #, #, /checi/D2287, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [D3145/D3148, [上海虹桥, 06:40, 厦门北, 14:45, 8小时5分, 1109, 388, 621, 0/0/0, 0/0, 400|10|1]], [G1651, [上海虹桥, 06:55, 厦门北, 13:38, 6小时43分, 1104, ...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8E%A6%E9%97%A8, #, #, #, #, #, #, #, #, #, #, #, #, /checi/D3145/D3148, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4571, [上海虹桥, 00:38, 南昌西, 03:45, 3小时7分, 741, 336.5, 560.5, 0/0/0, 0/0, 38|10|1]], [G4913, [上海虹桥, 01:05, 南昌西, 04:12, 3小时7分, 741, 336.5,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E6%98%8C, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4571, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4110/G4111, [上海虹桥, 01:12, 徐州东, 03:42, 2小时30分, 626, 279, 474, 0/0/0, 0/0, 72|10|1]], [K4168/K4169, [上海, 01:45, 徐州, 10:19, 8小时34分, 649,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%BE%90%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/G4110/G4111, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G222/G223, [上海, 07:05, 青岛北, 13:24, 6小时19分, 1300, 522, 822.5, 0/0/0, 0/0, 425|10|1]], [G230/G231, [上海虹桥, 08:52, 青岛, 16:01, 7小时9分, 1308,...</td>\n",
       "      <td>[http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E9%9D%92%E5%B2%9B, #, #, #, #, #, #, #, #, #, #, #, /checi/G222/G223, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.huoc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       text  \\\n",
       "0   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 南京南, 01:58, 0分, 295, 134.5, 229.5, 0/0/0, 0/0, 50|10|1]], [G9376/G9377, [上海, 00:58, 南京南, 02:29, 1小时31分, 311...   \n",
       "1   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G102, [上海虹桥, 06:26, 北京南, 12:29, 6小时3分, 1318, 606, 971, 0/0/0, 0/0, 386|10|1]], [G104, [上海虹桥, 06:37, 北京南, 12:33, 5小时56分, 1318, 606, 971...   \n",
       "2   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 苏州, 02:14, 1小时3分, 84, 7, -, 41/65.5/68.5, 90.5/96.5, 71|8|1]], [K5550/K5551, [上海, 01:11, 苏州, 02:14, 1小时3分, 84...   \n",
       "3   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4571, [上海虹桥, 00:38, 杭州东, 01:23, 45分, 159, 73, 117, 0/0/0, 0/0, 38|10|1]], [K4085, [上海南, 01:02, 杭州东, 02:52, 1小时50分, 167, 24.5, -, 70.5...   \n",
       "4   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4110/G4111, [上海虹桥, 01:12, 郑州东, 05:20, 4小时8分, 986, 482.5, 784.5, 0/0/0, 0/0, 72|10|1]], [K4168/K4169, [上海, 01:45, 郑州, 16:18, 14小时33分, ...   \n",
       "5   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K4085, [上海南, 01:02, 成都, 13:15, 36小时13分, 2473, 263.5, -, 446.5/462.5/477.5, 704.5/735.5, 62|8|1]], [K4616/K4617, [上海, 03:40, 成都, 11:50,...   \n",
       "6   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G108, [上海虹桥, 07:22, 天津南, 12:45, 5小时23分, 1196, 551, 881, 0/0/0, 0/0, 442|10|1]], [G1229/G1232, [上海虹桥, 07:34, 天津西, 13:45, 6小时11分, 1213, ...   \n",
       "7   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G85, [上海虹桥, 08:00, 广州南, 14:51, 6小时51分, 1790, 793, 1302.5, 0/0/0, 0/0, 480|10|1]], [G1301, [上海虹桥, 10:24, 广州南, 19:02, 8小时38分, 1790, 793,...   \n",
       "8   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 合肥南, 03:04, 0分, 468, 202.5, 335, 0/0/0, 0/0, 50|10|1]], [D4678/D4679, [上海虹桥, 01:17, 合肥南, 03:31, 2小时14分, 468...   \n",
       "9   [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 无锡, 02:47, 1小时36分, 126, 10.5, -, 65.5/70.5/73.5, 99.5/105.5, 71|8|1]], [K5550/K5551, [上海, 01:11, 无锡, 02:47, 1...   \n",
       "10  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K4028/K4025, [上海, 02:06, 西安, 23:48, 21小时42分, 1509, 180.5, -, 310.5/321.5/331.5, 488.5/509.5, 126|8|1]], [G4056/G4057, [上海虹桥, 02:16, 西安...   \n",
       "11  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4282/G4283, [上海虹桥, 05:45, 济南西, 09:48, 4小时3分, 912, 398.5, 673.5, 0/0/0, 0/0, 345|10|1]], [G456/G457, [上海虹桥, 06:05, 济南, 10:36, 4小时31分, ...   \n",
       "12  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K335/K338, [上海南, 05:02, 宁波, 09:38, 4小时36分, 332, -, -, 0/0/0, 0/0, 302|8|2]], [G7541, [上海虹桥, 06:00, 宁波, 07:50, 1小时50分, 314, 144, 237, 0...   \n",
       "13  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4824/G4825, [上海虹桥, 00:50, 武汉, 04:45, 0分, 807, 301, 425.5, 0/0/0, 0/0, 50|10|1]], [G4828/G4829, [上海虹桥, 01:46, 武汉, 05:28, 3小时42分, 807, ...   \n",
       "14  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [K5550/K5551, [上海, 01:11, 常州, 03:19, 2小时8分, 165, 24.5, -, 70.5/75.5/78.5, 108.5/114.5, 71|8|1]], [K4168/K4169, [上海, 01:45, 常州, 03:53, 2...   \n",
       "15  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [D2287, [上海虹桥, 07:02, 深圳北, 18:25, 11小时23分, 1892, 481, 597, 0/0/0, 0/0, 422|10|1]], [D377, [上海虹桥, 07:46, 深圳北, 19:25, 11小时39分, 1623, 568,...   \n",
       "16  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [D3145/D3148, [上海虹桥, 06:40, 厦门北, 14:45, 8小时5分, 1109, 388, 621, 0/0/0, 0/0, 400|10|1]], [G1651, [上海虹桥, 06:55, 厦门北, 13:38, 6小时43分, 1104, ...   \n",
       "17  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4571, [上海虹桥, 00:38, 南昌西, 03:45, 3小时7分, 741, 336.5, 560.5, 0/0/0, 0/0, 38|10|1]], [G4913, [上海虹桥, 01:05, 南昌西, 04:12, 3小时7分, 741, 336.5,...   \n",
       "18  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G4110/G4111, [上海虹桥, 01:12, 徐州东, 03:42, 2小时30分, 626, 279, 474, 0/0/0, 0/0, 72|10|1]], [K4168/K4169, [上海, 01:45, 徐州, 10:19, 8小时34分, 649,...   \n",
       "19  [[车次, 出发站, 开车时间, 到达站, 到达时间, 用时, 里程, 硬座, 软座, 硬卧上/中/下, 软卧上/下], [G222/G223, [上海, 07:05, 青岛北, 13:24, 6小时19分, 1300, 522, 822.5, 0/0/0, 0/0, 425|10|1]], [G230/G231, [上海虹桥, 08:52, 青岛, 16:01, 7小时9分, 1308,...   \n",
       "\n",
       "                                                                                                                                                                                                        url  \n",
       "0   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....  \n",
       "1   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8C%97%E4%BA%AC, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G102, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoc...  \n",
       "2   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E8%8B%8F%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...  \n",
       "3   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%9D%AD%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/G4571, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoche...  \n",
       "4   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E9%83%91%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4110/G4111, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...  \n",
       "5   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%88%90%E9%83%BD, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K4085, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海南, http://search.huoc...  \n",
       "6   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%A4%A9%E6%B4%A5, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G108, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoc...  \n",
       "7   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%B9%BF%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G85, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huoch...  \n",
       "8   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%90%88%E8%82%A5, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....  \n",
       "9   [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%97%A0%E9%94%A1, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...  \n",
       "10  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E8%A5%BF%E5%AE%89, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K4028/K4025, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search...  \n",
       "11  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%B5%8E%E5%8D%97, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4282/G4283, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...  \n",
       "12  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%AE%81%E6%B3%A2, #, #, #, #, #, #, #, #, #, #, #, #, /checi/K335/K338, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海南, http://search....  \n",
       "13  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%AD%A6%E6%B1%89, #, #, #, #, #, #, #, #, #, #, #, /checi/G4824/G4825, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....  \n",
       "14  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%B8%B8%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/K5550/K5551, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.hu...  \n",
       "15  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E6%B7%B1%E5%9C%B3, #, #, #, #, #, #, #, #, #, #, #, #, /checi/D2287, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huo...  \n",
       "16  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8E%A6%E9%97%A8, #, #, #, #, #, #, #, #, #, #, #, #, /checi/D3145/D3148, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://sear...  \n",
       "17  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%8D%97%E6%98%8C, #, #, #, #, #, #, #, #, #, #, #, #, /checi/G4571, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search.huo...  \n",
       "18  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E5%BE%90%E5%B7%9E, #, #, #, #, #, #, #, #, #, #, #, /checi/G4110/G4111, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海虹桥, http://search....  \n",
       "19  [http://www.guabu.com/zj_%E4%B8%8A%E6%B5%B7_%E9%9D%92%E5%B2%9B, #, #, #, #, #, #, #, #, #, #, #, /checi/G222/G223, http://search.huochepiao.com/chaxun/resultz.asp?txtChezhan=上海, http://search.huoc...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_schedule_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.broadway.com/shows/tickets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://www.broadway.com/shows/tickets/\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<a class=\"link-111-111\" href=\"/shows/to-kill-mockingbird/\" translate=\"no\">To Kill a Mockingbird</a>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv:nth-of-type(4) > div.card.card--hover.card--shadow.bg-white.mtn > div.card__body > div.media > div.media-body:nth-of-type(2) > h2.futura-pt.font-22-xs.font-36-sm.lh-1.ls-negative-05.mhn.mtn.mbr-15 > a.link-111-111\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>/shows/to-kill-mockingbird/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamilton</td>\n",
       "      <td>/shows/hamilton-broadway/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wicked</td>\n",
       "      <td>/shows/wicked/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moulin Rouge! The Musical</td>\n",
       "      <td>/shows/moulin-rouge-musical/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Phantom of the Opera</td>\n",
       "      <td>/shows/the-phantom-of-the-opera/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>/shows/the-lion-king/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Book of Mormon</td>\n",
       "      <td>/shows/book-mormon/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ain't Too Proud – The Life and Times of The Temptations</td>\n",
       "      <td>/shows/aint-too-proud/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aladdin</td>\n",
       "      <td>/shows/aladdin-broadway/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tina: The Tina Turner Musical</td>\n",
       "      <td>/shows/tina-tina-turner-musical/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Come From Away</td>\n",
       "      <td>/shows/come-away/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hadestown</td>\n",
       "      <td>/shows/hadestown/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dear Evan Hansen</td>\n",
       "      <td>/shows/dear-evan-hansen/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>/shows/chicago/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mrs. Doubtfire</td>\n",
       "      <td>/shows/mrs-doubtfire/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Company</td>\n",
       "      <td>/shows/company/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Jagged Little Pill</td>\n",
       "      <td>/shows/jagged-little-pill/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Harry Potter and the Cursed Child</td>\n",
       "      <td>/shows/harry-potter-and-cursed-child-broadway/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Girl From the North Country</td>\n",
       "      <td>/shows/girl-north-from-the-country/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Diana</td>\n",
       "      <td>/shows/diana/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text  \\\n",
       "0                                     To Kill a Mockingbird   \n",
       "1                                                  Hamilton   \n",
       "2                                                    Wicked   \n",
       "3                                 Moulin Rouge! The Musical   \n",
       "4                                  The Phantom of the Opera   \n",
       "5                                             The Lion King   \n",
       "6                                        The Book of Mormon   \n",
       "7   Ain't Too Proud – The Life and Times of The Temptations   \n",
       "8                                                   Aladdin   \n",
       "9                             Tina: The Tina Turner Musical   \n",
       "10                                           Come From Away   \n",
       "11                                                Hadestown   \n",
       "12                                         Dear Evan Hansen   \n",
       "13                                                  Chicago   \n",
       "14                                           Mrs. Doubtfire   \n",
       "15                                                  Company   \n",
       "16                                       Jagged Little Pill   \n",
       "17                        Harry Potter and the Cursed Child   \n",
       "18                              Girl From the North Country   \n",
       "19                                                    Diana   \n",
       "\n",
       "                                               url  \n",
       "0                      /shows/to-kill-mockingbird/  \n",
       "1                        /shows/hamilton-broadway/  \n",
       "2                                   /shows/wicked/  \n",
       "3                     /shows/moulin-rouge-musical/  \n",
       "4                 /shows/the-phantom-of-the-opera/  \n",
       "5                            /shows/the-lion-king/  \n",
       "6                              /shows/book-mormon/  \n",
       "7                           /shows/aint-too-proud/  \n",
       "8                         /shows/aladdin-broadway/  \n",
       "9                 /shows/tina-tina-turner-musical/  \n",
       "10                               /shows/come-away/  \n",
       "11                               /shows/hadestown/  \n",
       "12                        /shows/dear-evan-hansen/  \n",
       "13                                 /shows/chicago/  \n",
       "14                           /shows/mrs-doubtfire/  \n",
       "15                                 /shows/company/  \n",
       "16                      /shows/jagged-little-pill/  \n",
       "17  /shows/harry-potter-and-cursed-child-broadway/  \n",
       "18             /shows/girl-north-from-the-country/  \n",
       "19                                   /shows/diana/  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where('to kill a mockingbird', 'https://www.broadway.com/shows/tickets/')\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Success] The website at \"https://www.broadway.com/shows/tickets/\" is collected successfully.\n",
      "0\n",
      "\n",
      "Unique match is found:\n",
      "<a class=\"link-111-111\" href=\"/shows/to-kill-mockingbird/\" translate=\"no\">To Kill a Mockingbird</a>\n",
      "\n",
      "\n",
      "\n",
      "Extracting contents ...\n",
      "\n",
      "\n",
      "[Success] The selector path used to extract contents is:\n",
      "\n",
      "\tdiv:nth-of-type(4) > div.card.card--hover.card--shadow.bg-white.mtn > div.card__body > div.media > div.media-body:nth-of-type(2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[To Kill a Mockingbird, [['from ', '$69.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                            ...</td>\n",
       "      <td>[/shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Hamilton, [['from ', '$149.00'], 2hrs, 55mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2016 Tony Nominees,, 2016 Tony Winners]], [[                                              ...</td>\n",
       "      <td>[/shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Wicked, [['from ', '$95.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Bestsellers,, Musicals,, Kid-Friendly,, Comedy,, Award Winning]], [[                                                    ...</td>\n",
       "      <td>[/shows/wicked/, /shows/wicked/, /shows/wicked/, /shows/wicked/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[Moulin Rouge! The Musical, [['from ', '$59.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, 2020 Tony Nominees]], [[                                                        B...</td>\n",
       "      <td>[/shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[The Phantom of the Opera, [['from ', '$29.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Classics,, Drama,, Award Winning]], [[                                                     ...</td>\n",
       "      <td>[/shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[The Lion King, [['from ', '$75.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Dance,, Award Winning]], [[                                                        Buy ...</td>\n",
       "      <td>[/shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[The Book of Mormon, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, Award Winning,, 2011 Tony Winners]], [[                                                 ...</td>\n",
       "      <td>[/shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[Ain't Too Proud – The Life and Times of The Temptations, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                ...</td>\n",
       "      <td>[/shows/aint-too-proud/, /shows/aint-too-proud/, https://checkout.broadway.com/aint-too-proud/12714/calendar/, /shows/aint-too-proud/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[Aladdin, [['from ', '$57.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Comedy,, Award Winning,, 2014 Tony Winners]], [[                                             ...</td>\n",
       "      <td>[/shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[Tina: The Tina Turner Musical, [['from ', '$79.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[Come From Away, [['from ', '$49.00'], 1hr, 40mins], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                                        Buy...</td>\n",
       "      <td>[/shows/come-away/, /shows/come-away/, /shows/come-away/, /shows/come-away/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[Hadestown, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/hadestown/, /shows/hadestown/, /shows/hadestown/, /shows/hadestown/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[Dear Evan Hansen, [['from ', '$89.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                       ...</td>\n",
       "      <td>[/shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[Chicago, [['from ', '$49.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Dance,, Classics,, Comedy,, Award Winning,, Mature Audiences]], [[                                          ...</td>\n",
       "      <td>[/shows/chicago/, /shows/chicago/, https://checkout.broadway.com/chicago/12297/calendar/, /shows/chicago/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[Mrs. Doubtfire, [['from ', '$59.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                           ...</td>\n",
       "      <td>[/shows/mrs-doubtfire/, /shows/mrs-doubtfire/, https://checkout.broadway.com/mrs-doubtfire/12900/calendar/, /shows/mrs-doubtfire/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[Company, [['from ', '$59.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                         ...</td>\n",
       "      <td>[/shows/company/, /shows/company/, /shows/company/, /shows/company/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[Jagged Little Pill, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Tickets], [  ...</td>\n",
       "      <td>[/shows/jagged-little-pill/, /shows/jagged-little-pill/, https://checkout.broadway.com/jagged-little-pill/12812/calendar/, /shows/jagged-little-pill/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[Harry Potter and the Cursed Child, [from , $40.00], [Broadway,, Plays,, Award Winning,, 2018 Tony Nominees,, 2018 Tony Winners]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[Girl From the North Country, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [              ...</td>\n",
       "      <td>[/shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[Diana, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                    ...</td>\n",
       "      <td>[/shows/diana/, /shows/diana/, /shows/diana/, /shows/diana/]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       text  \\\n",
       "0   [[To Kill a Mockingbird, [['from ', '$69.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                            ...   \n",
       "1   [[Hamilton, [['from ', '$149.00'], 2hrs, 55mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2016 Tony Nominees,, 2016 Tony Winners]], [[                                              ...   \n",
       "2   [[Wicked, [['from ', '$95.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Bestsellers,, Musicals,, Kid-Friendly,, Comedy,, Award Winning]], [[                                                    ...   \n",
       "3   [[Moulin Rouge! The Musical, [['from ', '$59.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, 2020 Tony Nominees]], [[                                                        B...   \n",
       "4   [[The Phantom of the Opera, [['from ', '$29.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Classics,, Drama,, Award Winning]], [[                                                     ...   \n",
       "5   [[The Lion King, [['from ', '$75.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Dance,, Award Winning]], [[                                                        Buy ...   \n",
       "6   [[The Book of Mormon, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, Award Winning,, 2011 Tony Winners]], [[                                                 ...   \n",
       "7   [[Ain't Too Proud – The Life and Times of The Temptations, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                ...   \n",
       "8   [[Aladdin, [['from ', '$57.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Comedy,, Award Winning,, 2014 Tony Winners]], [[                                             ...   \n",
       "9   [[Tina: The Tina Turner Musical, [['from ', '$79.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Ti...   \n",
       "10  [[Come From Away, [['from ', '$49.00'], 1hr, 40mins], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                                        Buy...   \n",
       "11  [[Hadestown, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                                                        Buy Ti...   \n",
       "12  [[Dear Evan Hansen, [['from ', '$89.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                       ...   \n",
       "13  [[Chicago, [['from ', '$49.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Dance,, Classics,, Comedy,, Award Winning,, Mature Audiences]], [[                                          ...   \n",
       "14  [[Mrs. Doubtfire, [['from ', '$59.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                           ...   \n",
       "15  [[Company, [['from ', '$59.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                         ...   \n",
       "16  [[Jagged Little Pill, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Tickets], [  ...   \n",
       "17  [[Harry Potter and the Cursed Child, [from , $40.00], [Broadway,, Plays,, Award Winning,, 2018 Tony Nominees,, 2018 Tony Winners]], [[                                                        Buy Ti...   \n",
       "18  [[Girl From the North Country, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [              ...   \n",
       "19  [[Diana, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                    ...   \n",
       "\n",
       "                                                                                                                                                                                                 url  \n",
       "0                                                                               [/shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/]  \n",
       "1                                                                                       [/shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/]  \n",
       "2                                                                                                                                   [/shows/wicked/, /shows/wicked/, /shows/wicked/, /shows/wicked/]  \n",
       "3                                                                           [/shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/]  \n",
       "4                                                           [/shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/]  \n",
       "5                                                                                                       [/shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/]  \n",
       "6                                                                                                               [/shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/]  \n",
       "7                                                             [/shows/aint-too-proud/, /shows/aint-too-proud/, https://checkout.broadway.com/aint-too-proud/12714/calendar/, /shows/aint-too-proud/]  \n",
       "8                                                                                           [/shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/]  \n",
       "9                                                           [/shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/]  \n",
       "10                                                                                                                      [/shows/come-away/, /shows/come-away/, /shows/come-away/, /shows/come-away/]  \n",
       "11                                                                                                                      [/shows/hadestown/, /shows/hadestown/, /shows/hadestown/, /shows/hadestown/]  \n",
       "12                                                                                          [/shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/]  \n",
       "13                                                                                        [/shows/chicago/, /shows/chicago/, https://checkout.broadway.com/chicago/12297/calendar/, /shows/chicago/]  \n",
       "14                                                                [/shows/mrs-doubtfire/, /shows/mrs-doubtfire/, https://checkout.broadway.com/mrs-doubtfire/12900/calendar/, /shows/mrs-doubtfire/]  \n",
       "15                                                                                                                              [/shows/company/, /shows/company/, /shows/company/, /shows/company/]  \n",
       "16                                            [/shows/jagged-little-pill/, /shows/jagged-little-pill/, https://checkout.broadway.com/jagged-little-pill/12812/calendar/, /shows/jagged-little-pill/]  \n",
       "17  [/shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/]  \n",
       "18                                              [/shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/]  \n",
       "19                                                                                                                                      [/shows/diana/, /shows/diana/, /shows/diana/, /shows/diana/]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_contents, path = scrape_what_from_where('to kill a mockingbird', 'https://www.broadway.com/shows/tickets/', go_up = 2)\n",
    "extracted_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = create_page_url_list(template_url = 'https://www.broadway.com/shows/tickets/?page=NUMBER', start_index = 1, end_index = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3, 1/3, 2/3, \n",
      "\n",
      "[Success] Content extraction finished.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "broadway_show_df = extract_path_from_pages(path, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[To Kill a Mockingbird, [['from ', '$69.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                            ...</td>\n",
       "      <td>[/shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[Hamilton, [['from ', '$149.00'], 2hrs, 55mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2016 Tony Nominees,, 2016 Tony Winners]], [[                                              ...</td>\n",
       "      <td>[/shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[Wicked, [['from ', '$95.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Bestsellers,, Musicals,, Kid-Friendly,, Comedy,, Award Winning]], [[                                                    ...</td>\n",
       "      <td>[/shows/wicked/, /shows/wicked/, /shows/wicked/, /shows/wicked/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[Moulin Rouge! The Musical, [['from ', '$59.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, 2020 Tony Nominees]], [[                                                        B...</td>\n",
       "      <td>[/shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[The Phantom of the Opera, [['from ', '$29.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Classics,, Drama,, Award Winning]], [[                                                     ...</td>\n",
       "      <td>[/shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[The Lion King, [['from ', '$75.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Dance,, Award Winning]], [[                                                        Buy ...</td>\n",
       "      <td>[/shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[The Book of Mormon, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, Award Winning,, 2011 Tony Winners]], [[                                                 ...</td>\n",
       "      <td>[/shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[Ain't Too Proud – The Life and Times of The Temptations, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                ...</td>\n",
       "      <td>[/shows/aint-too-proud/, /shows/aint-too-proud/, https://checkout.broadway.com/aint-too-proud/12714/calendar/, /shows/aint-too-proud/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[Aladdin, [['from ', '$57.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Comedy,, Award Winning,, 2014 Tony Winners]], [[                                             ...</td>\n",
       "      <td>[/shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[Tina: The Tina Turner Musical, [['from ', '$79.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[Come From Away, [['from ', '$49.00'], 1hr, 40mins], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                                        Buy...</td>\n",
       "      <td>[/shows/come-away/, /shows/come-away/, /shows/come-away/, /shows/come-away/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[Hadestown, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/hadestown/, /shows/hadestown/, /shows/hadestown/, /shows/hadestown/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[Dear Evan Hansen, [['from ', '$89.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                       ...</td>\n",
       "      <td>[/shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[Chicago, [['from ', '$49.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Dance,, Classics,, Comedy,, Award Winning,, Mature Audiences]], [[                                          ...</td>\n",
       "      <td>[/shows/chicago/, /shows/chicago/, https://checkout.broadway.com/chicago/12297/calendar/, /shows/chicago/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[Mrs. Doubtfire, [['from ', '$59.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                           ...</td>\n",
       "      <td>[/shows/mrs-doubtfire/, /shows/mrs-doubtfire/, https://checkout.broadway.com/mrs-doubtfire/12900/calendar/, /shows/mrs-doubtfire/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[Company, [['from ', '$59.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                         ...</td>\n",
       "      <td>[/shows/company/, /shows/company/, /shows/company/, /shows/company/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[Jagged Little Pill, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Tickets], [  ...</td>\n",
       "      <td>[/shows/jagged-little-pill/, /shows/jagged-little-pill/, https://checkout.broadway.com/jagged-little-pill/12812/calendar/, /shows/jagged-little-pill/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[Harry Potter and the Cursed Child, [from , $40.00], [Broadway,, Plays,, Award Winning,, 2018 Tony Nominees,, 2018 Tony Winners]], [[                                                        Buy Ti...</td>\n",
       "      <td>[/shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[Girl From the North Country, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [              ...</td>\n",
       "      <td>[/shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[Diana, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                    ...</td>\n",
       "      <td>[/shows/diana/, /shows/diana/, /shows/diana/, /shows/diana/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[Jersey Boys, [['from ', '$59.00'], 2hrs, 30mins (1 Intermission)], [Off-Broadway,, Musicals,, Award Winner,, Award Winning,, Great for Dad]], [[                                                  ...</td>\n",
       "      <td>[/shows/jersey-boys/, /shows/jersey-boys/, https://checkout.broadway.com/jersey-boys/12940/calendar/, /shows/jersey-boys/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[Rock of Ages, [['from ', '$39.00'], 2hrs, 30min (1 Intermission)], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                          ...</td>\n",
       "      <td>[/shows/rock-of-ages/, /shows/rock-of-ages/, /shows/rock-of-ages/, /shows/rock-of-ages/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[The Play That Goes Wrong, [['from ', '$99.00'], 2hrs (1 Intermission)], [Off-Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [               ...</td>\n",
       "      <td>[/shows/play-goes-wrong-beginning-february-11-2019/, /shows/play-goes-wrong-beginning-february-11-2019/, https://checkout.broadway.com/play-goes-wrong-beginning-february-11-2019/12779/calendar/, /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[Blue Man Group, [['from ', '$82.50'], 1hr, 30mins], [Off-Broadway,, Kid-Friendly,, Comedy,, Special,, Great for Grad]], [[                                                        Buy Tickets], [ ...</td>\n",
       "      <td>[/shows/blue-man-group/, /shows/blue-man-group/, /shows/blue-man-group/, /shows/blue-man-group/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[Stomp, [['from ', '$49.50'], 1hr, 45mins], [Off-Broadway,, Kid-Friendly,, Dance,, Unique Events]], [[                                                        Buy Tickets], [                      ...</td>\n",
       "      <td>[/shows/stomp/, /shows/stomp/, /shows/stomp/, /shows/stomp/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[West Side Story, [['from ', '$49.00'], 1hr, 45mins], [Broadway,, Musicals,, Classics,, Drama]], [[                                                        Buy Tickets], [                         ...</td>\n",
       "      <td>[/shows/west-side-story/, /shows/west-side-story/, /shows/west-side-story/, /shows/west-side-story/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[The Music Man, [['from ', '$99.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Classics,, Comedy]], [[                                                        Buy Tickets], [                 ...</td>\n",
       "      <td>[/shows/music-man/, /shows/music-man/, /shows/music-man/, /shows/music-man/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[Six, [['from ', '$79.00'], TBA], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn M...</td>\n",
       "      <td>[/shows/six/, /shows/six/, /shows/six/, /shows/six/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[[Plaza Suite, [['from ', '$139.00'], 2hrs (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Comedy]], [[                                                        Buy Tickets], [              ...</td>\n",
       "      <td>[/shows/plaza-suite/, /shows/plaza-suite/, /shows/plaza-suite/, /shows/plaza-suite/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[[The Lehman Trilogy, [['from ', '$79.00'], TBA], [Broadway,, Plays,, Drama]], [[                                                        Buy Tickets], [                                            ...</td>\n",
       "      <td>[/shows/lehman-trilogy/, /shows/lehman-trilogy/, /shows/lehman-trilogy/, /shows/lehman-trilogy/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[[Little Shop of Horrors, [from , $69.00], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    ...</td>\n",
       "      <td>[/shows/little-shop-horrors/, /shows/little-shop-horrors/, /shows/little-shop-horrors/, /shows/little-shop-horrors/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[[American Buffalo, [['from ', '$99.50'], 2hrs (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama]], [[                                                        Buy Tickets], [           ...</td>\n",
       "      <td>[/shows/american-buffalo/, /shows/american-buffalo/, /shows/american-buffalo/, /shows/american-buffalo/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[[The Minutes, [['from ', '$49.00'], 1hr, 30mins], [Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [                                          ...</td>\n",
       "      <td>[/shows/minutes/, /shows/minutes/, /shows/minutes/, /shows/minutes/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[[MJ The Musical, [['from ', '$59.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                           ...</td>\n",
       "      <td>[/shows/mj/, /shows/mj/, /shows/mj/, /shows/mj/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[[Sing Street, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                              ...</td>\n",
       "      <td>[/shows/sing-street/, /shows/sing-street/, /shows/sing-street/, /shows/sing-street/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[[Gazillion Bubble Show, [['from ', '$59.00'], 1hr, 10mins (0 Intermission)], [Off-Broadway,, Kid-Friendly,, Comedy,, New,, Special]], [[                                                        Buy...</td>\n",
       "      <td>[/shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[[Trevor, [['from ', '$59.00'], TBA], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , ...</td>\n",
       "      <td>[/shows/trevor/, /shows/trevor/, /shows/trevor/, /shows/trevor/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[[David Byrne's American Utopia, [['from ', '$299.00'], 1hr, 40mins], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                             ...</td>\n",
       "      <td>[/shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[[Sistas, [['from ', '$44.50'], 1hr. 30mins (0 Intermission)], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                ...</td>\n",
       "      <td>[/shows/sistas/, /shows/sistas/, /shows/sistas/, /shows/sistas/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[[The Imbible: A Spirited History of Drinking, [['from ', '$89.00'], 1hr, 45mins (1 Intermission)], [Off-Broadway,, Musicals,, Comedy]], [[                                                        B...</td>\n",
       "      <td>[/shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[[Drunk Shakespeare, [['from ', '$55'], 90mins], [Off-Broadway,, Plays,, Mature Audiences]], [[                                                        Buy Tickets], [                              ...</td>\n",
       "      <td>[/shows/drunk-shakespeare/, /shows/drunk-shakespeare/, /shows/drunk-shakespeare/, /shows/drunk-shakespeare/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[[Take Me Out, TBA, [Broadway,, Plays]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/take-me-out/, /shows/take-me-out/, /shows/take-me-out/, /shows/take-me-out/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[[The Devil Wears Prada, [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/devil-wears-prada/, /shows/devil-wears-prada/, /shows/devil-wears-prada/, /shows/devil-wears-prada/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[[The Secret Garden, [Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/secret-garden/, /shows/secret-garden/, /shows/secret-garden/, /shows/secret-garden/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[[Flying Over Sunset, [['from ', '$97.00'], TBA], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                 ...</td>\n",
       "      <td>[/shows/flying-over-sunset/, /shows/flying-over-sunset/, /shows/flying-over-sunset/, /shows/flying-over-sunset/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[[1776, [Broadway,, Musicals,, Classics]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/1776/, /shows/1776/, /shows/1776/, /shows/1776/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[[Drift, [from , $79.00], [Off-Broadway,, Plays,, Drama]], [[                                                        Buy Tickets], [                                                    or , Learn M...</td>\n",
       "      <td>[/shows/drift/, /shows/drift/, /shows/drift/, /shows/drift/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[[Once Upon a One More Time, [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[[Caroline, or Change, [['from ', '$69.00'], TBA], [Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                        ...</td>\n",
       "      <td>[/shows/caroline-or-change/, /shows/caroline-or-change/, /shows/caroline-or-change/, /shows/caroline-or-change/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[[Assassins, [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/assassins-csc/, /shows/assassins-csc/, /shows/assassins-csc/, /shows/assassins-csc/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[[Birthday Candles, [['from ', '$49.00'], TBA], [Broadway,, Plays,, Stars on Stage,, Drama]], [[                                                        Buy Tickets], [                             ...</td>\n",
       "      <td>[/shows/birthday-candles/, /shows/birthday-candles/, /shows/birthday-candles/, /shows/birthday-candles/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[[Our Town, [Broadway,, Plays,, Classics,, Stars on Stage]], [[                                                        Buy Tickets], [                                                    or , Learn...</td>\n",
       "      <td>[/shows/our-town-2021/, /shows/our-town-2021/, /shows/our-town-2021/, /shows/our-town-2021/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[[Last Summer at Bluefish Cove, [Broadway,, Plays]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[[Intimate Apparel, [from , $92.00], [Off-Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                                  ...</td>\n",
       "      <td>[/shows/intimate-apparel/, /shows/intimate-apparel/, /shows/intimate-apparel/, /shows/intimate-apparel/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[[Half Time, [Broadway,, Musicals,, Dance]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]</td>\n",
       "      <td>[/shows/half-time/, /shows/half-time/, /shows/half-time/, /shows/half-time/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[[One Woman Sex and the City: A Parody of Love, Friendship and Shoes, [from , $31.00], [Off-Broadway,, Plays]], [[                                                        Buy Tickets], [           ...</td>\n",
       "      <td>[/shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, /shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, /shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[[Between the Lines, [from , $55.00], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , ...</td>\n",
       "      <td>[/shows/between-lines/, /shows/between-lines/, /shows/between-lines/, /shows/between-lines/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[[The Ride, [['from ', '$74.00'], 1hr, 15mins], [Off-Broadway,, Unique Events]], [[                                                        Buy Tickets], [                                          ...</td>\n",
       "      <td>[/shows/ride/, /shows/ride/, /shows/ride/, /shows/ride/]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[[Exception to the Rule, [from , $30.00], [Off-Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [                                               ...</td>\n",
       "      <td>[/shows/exception-rule/, /shows/exception-rule/, /shows/exception-rule/, /shows/exception-rule/]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       text  \\\n",
       "0   [[To Kill a Mockingbird, [['from ', '$69.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                            ...   \n",
       "1   [[Hamilton, [['from ', '$149.00'], 2hrs, 55mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2016 Tony Nominees,, 2016 Tony Winners]], [[                                              ...   \n",
       "2   [[Wicked, [['from ', '$95.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Bestsellers,, Musicals,, Kid-Friendly,, Comedy,, Award Winning]], [[                                                    ...   \n",
       "3   [[Moulin Rouge! The Musical, [['from ', '$59.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, 2020 Tony Nominees]], [[                                                        B...   \n",
       "4   [[The Phantom of the Opera, [['from ', '$29.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Classics,, Drama,, Award Winning]], [[                                                     ...   \n",
       "5   [[The Lion King, [['from ', '$75.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Dance,, Award Winning]], [[                                                        Buy ...   \n",
       "6   [[The Book of Mormon, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Comedy,, Award Winning,, 2011 Tony Winners]], [[                                                 ...   \n",
       "7   [[Ain't Too Proud – The Life and Times of The Temptations, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                ...   \n",
       "8   [[Aladdin, [['from ', '$57.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Kid-Friendly,, Comedy,, Award Winning,, 2014 Tony Winners]], [[                                             ...   \n",
       "9   [[Tina: The Tina Turner Musical, [['from ', '$79.00'], 2hrs, 45mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Ti...   \n",
       "10  [[Come From Away, [['from ', '$49.00'], 1hr, 40mins], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                                        Buy...   \n",
       "11  [[Hadestown, [['from ', '$69.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2019 Tony Nominees,, 2019 Tony Winners]], [[                                                        Buy Ti...   \n",
       "12  [[Dear Evan Hansen, [['from ', '$89.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Award Winning,, 2017 Tony Nominees,, 2017 Tony Winners]], [[                                       ...   \n",
       "13  [[Chicago, [['from ', '$49.50'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, Dance,, Classics,, Comedy,, Award Winning,, Mature Audiences]], [[                                          ...   \n",
       "14  [[Mrs. Doubtfire, [['from ', '$59.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                           ...   \n",
       "15  [[Company, [['from ', '$59.00'], 2hrs, 35mins (1 Intermission)], [Broadway,, Musicals,, Comedy]], [[                                                        Buy Tickets], [                         ...   \n",
       "16  [[Jagged Little Pill, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals,, 2020 Tony Nominees]], [[                                                        Buy Tickets], [  ...   \n",
       "17  [[Harry Potter and the Cursed Child, [from , $40.00], [Broadway,, Plays,, Award Winning,, 2018 Tony Nominees,, 2018 Tony Winners]], [[                                                        Buy Ti...   \n",
       "18  [[Girl From the North Country, [['from ', '$49.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [              ...   \n",
       "19  [[Diana, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                    ...   \n",
       "20  [[Jersey Boys, [['from ', '$59.00'], 2hrs, 30mins (1 Intermission)], [Off-Broadway,, Musicals,, Award Winner,, Award Winning,, Great for Dad]], [[                                                  ...   \n",
       "21  [[Rock of Ages, [['from ', '$39.00'], 2hrs, 30min (1 Intermission)], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                          ...   \n",
       "22  [[The Play That Goes Wrong, [['from ', '$99.00'], 2hrs (1 Intermission)], [Off-Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [               ...   \n",
       "23  [[Blue Man Group, [['from ', '$82.50'], 1hr, 30mins], [Off-Broadway,, Kid-Friendly,, Comedy,, Special,, Great for Grad]], [[                                                        Buy Tickets], [ ...   \n",
       "24  [[Stomp, [['from ', '$49.50'], 1hr, 45mins], [Off-Broadway,, Kid-Friendly,, Dance,, Unique Events]], [[                                                        Buy Tickets], [                      ...   \n",
       "25  [[West Side Story, [['from ', '$49.00'], 1hr, 45mins], [Broadway,, Musicals,, Classics,, Drama]], [[                                                        Buy Tickets], [                         ...   \n",
       "26  [[The Music Man, [['from ', '$99.00'], TBA (1 Intermission)], [Broadway,, Musicals,, Classics,, Comedy]], [[                                                        Buy Tickets], [                 ...   \n",
       "27  [[Six, [['from ', '$79.00'], TBA], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn M...   \n",
       "28  [[Plaza Suite, [['from ', '$139.00'], 2hrs (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Comedy]], [[                                                        Buy Tickets], [              ...   \n",
       "29  [[The Lehman Trilogy, [['from ', '$79.00'], TBA], [Broadway,, Plays,, Drama]], [[                                                        Buy Tickets], [                                            ...   \n",
       "30  [[Little Shop of Horrors, [from , $69.00], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    ...   \n",
       "31  [[American Buffalo, [['from ', '$99.50'], 2hrs (1 Intermission)], [Broadway,, Plays,, Stars on Stage,, Drama]], [[                                                        Buy Tickets], [           ...   \n",
       "32  [[The Minutes, [['from ', '$49.00'], 1hr, 30mins], [Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [                                          ...   \n",
       "33  [[MJ The Musical, [['from ', '$59.00'], 2hrs, 30mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                           ...   \n",
       "34  [[Sing Street, [['from ', '$49.00'], 2hrs, 15mins (1 Intermission)], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                              ...   \n",
       "35  [[Gazillion Bubble Show, [['from ', '$59.00'], 1hr, 10mins (0 Intermission)], [Off-Broadway,, Kid-Friendly,, Comedy,, New,, Special]], [[                                                        Buy...   \n",
       "36  [[Trevor, [['from ', '$59.00'], TBA], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , ...   \n",
       "37  [[David Byrne's American Utopia, [['from ', '$299.00'], 1hr, 40mins], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                             ...   \n",
       "38  [[Sistas, [['from ', '$44.50'], 1hr. 30mins (0 Intermission)], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                ...   \n",
       "39  [[The Imbible: A Spirited History of Drinking, [['from ', '$89.00'], 1hr, 45mins (1 Intermission)], [Off-Broadway,, Musicals,, Comedy]], [[                                                        B...   \n",
       "40  [[Drunk Shakespeare, [['from ', '$55'], 90mins], [Off-Broadway,, Plays,, Mature Audiences]], [[                                                        Buy Tickets], [                              ...   \n",
       "41                 [[Take Me Out, TBA, [Broadway,, Plays]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "42         [[The Devil Wears Prada, [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "43     [[The Secret Garden, [Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "44  [[Flying Over Sunset, [['from ', '$97.00'], TBA], [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                 ...   \n",
       "45               [[1776, [Broadway,, Musicals,, Classics]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "46  [[Drift, [from , $79.00], [Off-Broadway,, Plays,, Drama]], [[                                                        Buy Tickets], [                                                    or , Learn M...   \n",
       "47     [[Once Upon a One More Time, [Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "48  [[Caroline, or Change, [['from ', '$69.00'], TBA], [Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                        ...   \n",
       "49                 [[Assassins, [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "50  [[Birthday Candles, [['from ', '$49.00'], TBA], [Broadway,, Plays,, Stars on Stage,, Drama]], [[                                                        Buy Tickets], [                             ...   \n",
       "51  [[Our Town, [Broadway,, Plays,, Classics,, Stars on Stage]], [[                                                        Buy Tickets], [                                                    or , Learn...   \n",
       "52     [[Last Summer at Bluefish Cove, [Broadway,, Plays]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "53  [[Intimate Apparel, [from , $92.00], [Off-Broadway,, Musicals,, Drama]], [[                                                        Buy Tickets], [                                                  ...   \n",
       "54             [[Half Time, [Broadway,, Musicals,, Dance]], [[                                                        Buy Tickets], [                                                    or , Learn More]]]   \n",
       "55  [[One Woman Sex and the City: A Parody of Love, Friendship and Shoes, [from , $31.00], [Off-Broadway,, Plays]], [[                                                        Buy Tickets], [           ...   \n",
       "56  [[Between the Lines, [from , $55.00], [Off-Broadway,, Musicals]], [[                                                        Buy Tickets], [                                                    or , ...   \n",
       "57  [[The Ride, [['from ', '$74.00'], 1hr, 15mins], [Off-Broadway,, Unique Events]], [[                                                        Buy Tickets], [                                          ...   \n",
       "58  [[Exception to the Rule, [from , $30.00], [Off-Broadway,, Plays,, Comedy]], [[                                                        Buy Tickets], [                                               ...   \n",
       "\n",
       "                                                                                                                                                                                                        url  \n",
       "0                                                                                      [/shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/, /shows/to-kill-mockingbird/]  \n",
       "1                                                                                              [/shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/, /shows/hamilton-broadway/]  \n",
       "2                                                                                                                                          [/shows/wicked/, /shows/wicked/, /shows/wicked/, /shows/wicked/]  \n",
       "3                                                                                  [/shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/, /shows/moulin-rouge-musical/]  \n",
       "4                                                                  [/shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/, /shows/the-phantom-of-the-opera/]  \n",
       "5                                                                                                              [/shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/, /shows/the-lion-king/]  \n",
       "6                                                                                                                      [/shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/, /shows/book-mormon/]  \n",
       "7                                                                    [/shows/aint-too-proud/, /shows/aint-too-proud/, https://checkout.broadway.com/aint-too-proud/12714/calendar/, /shows/aint-too-proud/]  \n",
       "8                                                                                                  [/shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/, /shows/aladdin-broadway/]  \n",
       "9                                                                  [/shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/, /shows/tina-tina-turner-musical/]  \n",
       "10                                                                                                                             [/shows/come-away/, /shows/come-away/, /shows/come-away/, /shows/come-away/]  \n",
       "11                                                                                                                             [/shows/hadestown/, /shows/hadestown/, /shows/hadestown/, /shows/hadestown/]  \n",
       "12                                                                                                 [/shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/, /shows/dear-evan-hansen/]  \n",
       "13                                                                                               [/shows/chicago/, /shows/chicago/, https://checkout.broadway.com/chicago/12297/calendar/, /shows/chicago/]  \n",
       "14                                                                       [/shows/mrs-doubtfire/, /shows/mrs-doubtfire/, https://checkout.broadway.com/mrs-doubtfire/12900/calendar/, /shows/mrs-doubtfire/]  \n",
       "15                                                                                                                                     [/shows/company/, /shows/company/, /shows/company/, /shows/company/]  \n",
       "16                                                   [/shows/jagged-little-pill/, /shows/jagged-little-pill/, https://checkout.broadway.com/jagged-little-pill/12812/calendar/, /shows/jagged-little-pill/]  \n",
       "17         [/shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/, /shows/harry-potter-and-cursed-child-broadway/]  \n",
       "18                                                     [/shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/, /shows/girl-north-from-the-country/]  \n",
       "19                                                                                                                                             [/shows/diana/, /shows/diana/, /shows/diana/, /shows/diana/]  \n",
       "20                                                                               [/shows/jersey-boys/, /shows/jersey-boys/, https://checkout.broadway.com/jersey-boys/12940/calendar/, /shows/jersey-boys/]  \n",
       "21                                                                                                                 [/shows/rock-of-ages/, /shows/rock-of-ages/, /shows/rock-of-ages/, /shows/rock-of-ages/]  \n",
       "22  [/shows/play-goes-wrong-beginning-february-11-2019/, /shows/play-goes-wrong-beginning-february-11-2019/, https://checkout.broadway.com/play-goes-wrong-beginning-february-11-2019/12779/calendar/, /...  \n",
       "23                                                                                                         [/shows/blue-man-group/, /shows/blue-man-group/, /shows/blue-man-group/, /shows/blue-man-group/]  \n",
       "24                                                                                                                                             [/shows/stomp/, /shows/stomp/, /shows/stomp/, /shows/stomp/]  \n",
       "25                                                                                                     [/shows/west-side-story/, /shows/west-side-story/, /shows/west-side-story/, /shows/west-side-story/]  \n",
       "26                                                                                                                             [/shows/music-man/, /shows/music-man/, /shows/music-man/, /shows/music-man/]  \n",
       "27                                                                                                                                                     [/shows/six/, /shows/six/, /shows/six/, /shows/six/]  \n",
       "28                                                                                                                     [/shows/plaza-suite/, /shows/plaza-suite/, /shows/plaza-suite/, /shows/plaza-suite/]  \n",
       "29                                                                                                         [/shows/lehman-trilogy/, /shows/lehman-trilogy/, /shows/lehman-trilogy/, /shows/lehman-trilogy/]  \n",
       "30                                                                                     [/shows/little-shop-horrors/, /shows/little-shop-horrors/, /shows/little-shop-horrors/, /shows/little-shop-horrors/]  \n",
       "31                                                                                                 [/shows/american-buffalo/, /shows/american-buffalo/, /shows/american-buffalo/, /shows/american-buffalo/]  \n",
       "32                                                                                                                                     [/shows/minutes/, /shows/minutes/, /shows/minutes/, /shows/minutes/]  \n",
       "33                                                                                                                                                         [/shows/mj/, /shows/mj/, /shows/mj/, /shows/mj/]  \n",
       "34                                                                                                                     [/shows/sing-street/, /shows/sing-street/, /shows/sing-street/, /shows/sing-street/]  \n",
       "35                                                                             [/shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/, /shows/gazillion-bubble-show/]  \n",
       "36                                                                                                                                         [/shows/trevor/, /shows/trevor/, /shows/trevor/, /shows/trevor/]  \n",
       "37                                                 [/shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/, /shows/david-byrnes-american-utopia/]  \n",
       "38                                                                                                                                         [/shows/sistas/, /shows/sistas/, /shows/sistas/, /shows/sistas/]  \n",
       "39                             [/shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/, /shows/imbible-spirited-history-drinking/]  \n",
       "40                                                                                             [/shows/drunk-shakespeare/, /shows/drunk-shakespeare/, /shows/drunk-shakespeare/, /shows/drunk-shakespeare/]  \n",
       "41                                                                                                                     [/shows/take-me-out/, /shows/take-me-out/, /shows/take-me-out/, /shows/take-me-out/]  \n",
       "42                                                                                             [/shows/devil-wears-prada/, /shows/devil-wears-prada/, /shows/devil-wears-prada/, /shows/devil-wears-prada/]  \n",
       "43                                                                                                             [/shows/secret-garden/, /shows/secret-garden/, /shows/secret-garden/, /shows/secret-garden/]  \n",
       "44                                                                                         [/shows/flying-over-sunset/, /shows/flying-over-sunset/, /shows/flying-over-sunset/, /shows/flying-over-sunset/]  \n",
       "45                                                                                                                                                 [/shows/1776/, /shows/1776/, /shows/1776/, /shows/1776/]  \n",
       "46                                                                                                                                             [/shows/drift/, /shows/drift/, /shows/drift/, /shows/drift/]  \n",
       "47                                                                     [/shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/, /shows/once-upon-one-more-time/]  \n",
       "48                                                                                         [/shows/caroline-or-change/, /shows/caroline-or-change/, /shows/caroline-or-change/, /shows/caroline-or-change/]  \n",
       "49                                                                                                             [/shows/assassins-csc/, /shows/assassins-csc/, /shows/assassins-csc/, /shows/assassins-csc/]  \n",
       "50                                                                                                 [/shows/birthday-candles/, /shows/birthday-candles/, /shows/birthday-candles/, /shows/birthday-candles/]  \n",
       "51                                                                                                             [/shows/our-town-2021/, /shows/our-town-2021/, /shows/our-town-2021/, /shows/our-town-2021/]  \n",
       "52                                                             [/shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/, /shows/last-summer-bluefish-cove/]  \n",
       "53                                                                                                 [/shows/intimate-apparel/, /shows/intimate-apparel/, /shows/intimate-apparel/, /shows/intimate-apparel/]  \n",
       "54                                                                                                                             [/shows/half-time/, /shows/half-time/, /shows/half-time/, /shows/half-time/]  \n",
       "55  [/shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, /shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, /shows/one-woman-sex-and-city-parody-love-friendship-and-shoes/, ...  \n",
       "56                                                                                                             [/shows/between-lines/, /shows/between-lines/, /shows/between-lines/, /shows/between-lines/]  \n",
       "57                                                                                                                                                 [/shows/ride/, /shows/ride/, /shows/ride/, /shows/ride/]  \n",
       "58                                                                                                         [/shows/exception-rule/, /shows/exception-rule/, /shows/exception-rule/, /shows/exception-rule/]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadway_show_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and To-dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the content of the website is collected, the next step is to parse the page. \n",
    "# After parsing, we can find the elements we want, then extract and clean their values. \n",
    "# For this step, there are many choices of libraries, some examples are: \n",
    "\n",
    "#  - BeautifulSoup\n",
    "#  - Scrapy\n",
    "#  - Lxml\n",
    "#  - AdvancedHTMLParser\n",
    " \n",
    "# In this pipeline, we will explore `BeautifulSoup`. `BeautifulSoup` and `Scrapy` are two popular scraping tools. Between these two, BeautifulSoup is more user-friendly, while Scrapy is more efficient and scalable. \n",
    "# As this pipeline is targeted for people with less technical backgrounds, we will sacrafice some efficiency for more intuitive experience.\n",
    "# If you are working on a large-scale or high-velocity scraping project, please consider Scrapy or other tool.\n",
    "# The other two libraries listed above are good choices in their specific areas, so keep them in view:\n",
    "#  - Lxml has rich features for processing XML and HTML and is quite efficient (BeautifulSoup actually supports using Lxml parser among other parsers).\n",
    "#  - AdvancedHTMLParser has similar functions like in native JavaScript and supports complex operations on HTML.\n",
    "  \n",
    "### Choices of Parsers\n",
    "# References:\n",
    "#  - https://smartproxy.com/blog/scrapy-vs-beautifulsoup (Use cases comparison and Pros&Cons)\n",
    "#  - https://tomassetti.me/parsing-html (Common libraries in different programming languages)\n",
    "#  - https://medium.com/analytics-vidhya/scrapy-vs-selenium-vs-beautiful-soup-for-web-scraping-24008b6c87b8 (Great comparison article that includes Selenium, which is the popular choice for dynamic website scraping)\n",
    "\n",
    "### Beautiful Soup\n",
    "# References:   \n",
    "#  - https://www.datacamp.com/community/tutorials/amazon-web-scraping-using-beautifulsoup (Showed how to write element finding logic in hierarchy)\n",
    "#  - https://stackabuse.com/guide-to-parsing-html-with-beautifulsoup-in-python (Nice illustrations, browse_and_scrape combines pagination with parsing) \n",
    "#  - https://www.crummy.com/software/BeautifulSoup/bs4/doc (Long but detailed description of BS4 usage)\n",
    "#  - https://www.crummy.com/software/BeautifulSoup (The \"Hall of Fame\" section has some high-profile projects, worth having a look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # To be implemented:\n",
    "\n",
    "# An interesting side note, here's one quote from the BS project page:\n",
    "# > You can tell it \"Find all the links\", or \"Find all the links of class externalLink\", or \"Find all the links whose urls match \"foo.com\", or \"Find the table heading that's got bold text, then give me that text.\"\n",
    "# But actually, you CANNOT directly ask BS these natural language questions. You need to write codes that follow the syntax of the BS4 library, which is similar but not quite close to natural language. \n",
    "# **Programming with natural language** is one of the directions worth pursuing in the future, as it further lowers the bar for utilizing web scraping and related technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # To be implemented:\n",
    "\n",
    "# Note the requests made by the `get_response` function might be recognized as robotic access by some website. \n",
    "# To bypass screening by those websites, additional specifications on headers and proxies are required. \n",
    "# These additional setup will be implemented in the future versions.\n",
    "\n",
    "# As a reference, the `get` function from the Python library requests takes the following parameters:\n",
    "# - url – URL for the new  Request object.\n",
    "# - params – (optional) Dictionary of GET Parameters to send with the Request.\n",
    "# - headers – (optional) Dictionary of HTTP Headers to send with the Request.\n",
    "# - cookies – (optional) CookieJar object to send with the  Request.\n",
    "# - auth – (optional) AuthObject to enable Basic HTTP Auth.\n",
    "# - timeout – (optional) Float describing the timeout of the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # To be integrated:\n",
    "# # When getting the response, use unicode-dammit to detect encodings in smart ways (https://www.crummy.com/software/BeautifulSoup/bs4/doc/#unicode-dammit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # To be implemented formally: Get next/prev sibling\n",
    "# for child in get_contents(sample_element.parent): # [::-1]\n",
    "#     print(child == sample_element) # if true then next is next sib or prev sib depending on how contents list is ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # Ready have open-source implementation, but :\n",
    "# # css_selector_to_xpath is getting a result that is too complicated\n",
    "# # xpath_to_css_selector cannot handle slightly more complex xpath\n",
    "# # For simple xpath-css conversion, own implementation might be more transparent and reliable\n",
    "\n",
    "# # !pip3 install cssify\n",
    "# # !pip3 install cssselect\n",
    "\n",
    "# # Reference: https://github.com/santiycr/cssify\n",
    "# from cssify import cssify\n",
    "# def xpath_to_css_selector(xpath_string):\n",
    "#     return cssify(xpath_string)\n",
    "\n",
    "# # Reference: https://lxml.de/cssselect.html\n",
    "# from cssselect import GenericTranslator\n",
    "# def css_selector_to_xpath(css_selector_string):\n",
    "#     return GenericTranslator().css_to_xpath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # $$$\n",
    "# # Implemented as a solution to indicate to the user which parts of the websites will be scraped\n",
    "# # However, this involves opening up the newly created html file in a browser and searching for changes\n",
    "# # The highlighting may not be obvious and the process is almost as complex as using broswer inspector\n",
    "# # Thus this functionality is dropped and should be kept in view (KIV)\n",
    "\n",
    "# def highlight_element(element, highlight_style = \"background-color: rgba(255,0,0,0.5); border: 3px dotted yellow\"):\n",
    "#     element['style'] = highlight_style\n",
    "\n",
    "# def highlight_elements(elements, highlight_style = \"background-color: rgba(255,0,0,0.5); border: 3px dotted yellow; \"):\n",
    "#     for element in elements:\n",
    "#         element['style'] = highlight_style\n",
    "\n",
    "# # highlighted_soup = highlight_element(soup.select(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# # Reference: How To Rotate Proxies and change IP Addresses using Python 3\n",
    "# # https://www.scrapehero.com/how-to-rotate-proxies-and-ip-addresses-using-python-3/    \n",
    "    \n",
    "# from lxml.html import fromstring\n",
    "# import requests\n",
    "# from itertools import cycle\n",
    "# import traceback\n",
    "\n",
    "# def get_proxies():\n",
    "#     url = 'https://free-proxy-list.net/'\n",
    "#     response = requests.get(url)\n",
    "#     parser = fromstring(response.text)\n",
    "#     proxies = set()\n",
    "#     for i in parser.xpath('//tbody/tr')[:10]:\n",
    "#         if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "#             proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "#             proxies.add(proxy)\n",
    "#     return proxies\n",
    "\n",
    "# #If you are copy pasting proxy ips, put in the list below\n",
    "# #proxies = ['121.129.127.209:80', '124.41.215.238:45169', '185.93.3.123:8080', '194.182.64.67:3128', '106.0.38.174:8080', '163.172.175.210:3128', '13.92.196.150:8080']\n",
    "# proxies = get_proxies()\n",
    "# proxy_pool = cycle(proxies)\n",
    "\n",
    "# url = 'https://httpbin.org/ip'\n",
    "# for i in range(1,11):\n",
    "#     #Get a proxy from the pool\n",
    "#     proxy = next(proxy_pool)\n",
    "#     print(\"Request #%d\"%i)\n",
    "#     try:\n",
    "#         response = requests.get(url,proxies={\"http\": proxy, \"https\": proxy})\n",
    "#         print(response.json())\n",
    "#     except:\n",
    "#         #Most free proxies will often get connection errors. You will have retry the entire request using another proxy to work. \n",
    "#         #We will just skip retries as its beyond the scope of this tutorial and we are only downloading a single url \n",
    "#         print(\"Skipping. Connnection error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
